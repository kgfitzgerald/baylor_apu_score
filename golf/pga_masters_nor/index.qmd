---
title: "PGA - Scoring Average Confidence Intervals (No R)"
author:
  - name: Jonathan Lieb
    email: jonathan_lieb1@baylor.edu
    affiliation:
      - id: bay
        name: Baylor University
date: July 24, 2024
format:
  html:
    grid:
      margin-width: 350px
toc: true
toc-location: left
description: Exploring Single Mean Confidence Intervals with Golf Data
categories:
  - Single Mean Confidence Intervals
  - Single Mean Hypothesis Testing
editor_options:
  chunk_output_type: console
callout-icon: false
---

::: {.callout-note collapse="true" title="Facilitation notes" appearance="minimal"}
+ This module would be suitable for an in-class lab or take-home assignment in an introductory statistics course. 

+ The data used to create this module and a student answer template can be downloaded from the following links:
  
  + [data](masters_2023.csv)
  + [Student Answer template](student_template.pdf)
:::

# Welcome video

<iframe width="560" height="315" src title="placeholder">

</iframe>

# Introduction

In this module, you will be exploring the concepts of single mean confidence intervals and single mean hypothesis tests using data from the 2023 Masters Tournament. The Masters is considered to be one of the greatest and most selective tournaments in the world of golf. Only the best current players or previous winners are allowed in. The winner of the Masters gets to wear the famed "Green Jacket" and return to play any year they would like at the Masters. The course the Masters is played at, Augusta National, is one of the most beautiful and challenging courses in the world. The course is known for its fast greens and tight fairways. The Masters is the first major of the year and is played in early April. The tournament is played over four days. After 2 days, the top 50 players and ties make the cut and play the final two days. 

::: column-margin
Scottie Scheffler after winning the 2023 Masters Tournament.

<!-- ![](masters_leaderboard.jpg) -->
<!-- Image Source: [The PGA](https://www.pga.com/story/masters-green-jacket-history-and-facts) -->

:::

::: column-margin

View the course at Augusta National [here](https://www.masters.com/en_US/course/index.html)

:::


As mentioned before, only the best players and previous winners can compete in the tournament. With that being said, the Masters is one of the few tournaments that players from the newly created LIV golf tour can play in, although they are mostly qualifying because of their past performances at the Masters before they joined LIV golf. This leads to a mixture of regular PGA professionals, LIV professionals, Amateurs, and Seniors playing in the Masters in 2023. 


The focus for this module is confidence intervals and hypothesis testing for the true mean scores for different groups of players at Augusta National. 

::: {.callout-note title="Learning Objectives" appearance="minimal"}
By the end of this module, you will be able to:

-   Make single mean confidence intervals

-   Perform a hypothesis test for a single mean
:::

::: {.callout-caution collapse="true" title="Research Questions"}

During this lab, you'll investigate the following research questions:

+ What are the confidence intervals for scoring for different groups of players at the 2023 Masters Tournament?
+ Is the true mean for different groups of players at the 2023 Masters different than par?
+ Is the true scoring average for amateurs greater than par at Augusta National?
+ How do sample size and confidence level affect the width of a confidence interval?

:::

# Getting started: 2023 Masters Data

The data for this lab comes from the 2023 Masters tournament. The data includes the name of golfer, the round of the tournament, the score the round, and the tour that they usually play on.

```{r, warning = FALSE, message = FALSE, echo = FALSE}
library(tidyverse)
library(BSDA)
library(kableExtra)

masters_2023 <- read_csv("masters_2023.csv")
```

::: {.callout-note collapse="true" title="Data Description"}

| Variable | Description |
|----|----------------------------|
| `player` | Golfer's name |
| `round` | Round of the tournament |
| `score` | Score for the 18-hole course |
| `tour` | The tour the player generally competes on |
:::

## Terms to know

Before proceeding with the analysis, let's make sure we know some important golf terminology that will help us master this lab.

#### Golf Terminology
-   **Par** in golf is the amount of strokes that a good golfer is expected to take to get the ball in the hole.
    - Each **hole** in golf has its own **par**. There are **par 3** holes, **par 4** holes, and **par 5** holes. 
    - There are 18 holes on a golf course and the **pars** of each of these holes sums to **par for the course**, also known the **course par**. 
-   A **round** in golf is when a golfer plays the full set of 18 holes on the course.
    - In most professional golf tournaments, all golfers play **2 rounds**, the best golfers are selected and those golfers play 2 more rounds for a total of **4 rounds**.


::: {.callout-important}

#### Types of Golf Tours
- In golf there are a few **tours**, better thought of as leagues, that golfers regularly compete in

     -  The **PGA**, or "Professional Golf Association", has long been considered the preeminant golfing tour, hosting most tournaments and containing the most skilled members.
     - The **LIV** tour is a Saudi-backed alternative to the PGA that was played its first season in 2022. **LIV** is the Roman numeral for 54 and is related to the fact that **LIV** tournaments only allow 54 players and only play 54 holes, compared to the normal PGA 72 holes.
     - The **PGA Tour Champions** is a branch off of the PGA tour for players 50 or older. It used to be called the "Senior PGA Tour" until 2003, when it began being called the **Champions** tour
     - An **amateur** is a golfer who is not yet a professional. They are not allowed to win money in professional golf tournaments. Most **amateurs** are college golfers. 

:::

::: column-margin

PGA vs. LIV

<!-- ![](pga-logo.png) -->

vs

<!-- ![](liv_logo.png) -->

<!-- Images Source: [PGA](https://www.pgatour.com/) and [LIV](https://www.livgolf.com/) -->

Click [here](https://www.si.com/golf/news/timeline-liv-golf-how-pga-tour-adapted) to read about LIV golf's founding and its continued impact on the PGA tour.

:::


# Single Mean Confidence Intervals

Single Mean confidence intervals give a range of numbers that we can feel confident that the true population mean falls between. 

There are two different ways of calculating the confidence interval for a single mean. 

## t-interval for single means

A t-distribution is used for calculating a single mean confidence interval if the sample size is small (rule of thumb: less than 30) and the population standard deviation is unknown. 

The formula for calculating a CI using this method is shown below:
$$CI = \bar{X} \pm t_{\alpha/2, df} \times \frac{S}{\sqrt{n}}$$

::: column-margin

Click [here](https://www.scribbr.com/statistics/t-distribution/) to learn more about the t-distribution and play around with t-distribution graphs.

:::

Where $\bar{X}$ is the sample mean,

$t_{\alpha/2, df}$ is the critical value for the t-distribution
with $df = n-1$,

$S$ is the sample standard deviation,

and $n$ is the sample size.

::: column-margin

**NOTE**: The t-distribution changes based on the degrees of freedom, approaching the normal distribution as the degrees of freedom increase.

:::

The critical value for the t-distribution is determined by the confidence level and the degrees of freedom. This is calculated by finding the value of $t_{\alpha/2, df}$ such that the area under the t-distribution curve (with that specific degrees of freedom) between $-t_{\alpha/2, df}$ and $t_{\alpha/2, df}$ is equal to the confidence level. 

```{r, echo=FALSE, warning=FALSE, message=FALSE}
df <- 10
confidence_level <- 0.95
alpha <- 1 - confidence_level

# Calculate the critical values for the 95% confidence interval
t_critical <- qt(1 - alpha/2, df)
neg_t_critical <- -t_critical

# Generate the t-distribution data
x <- seq(-4, 4, length.out = 400)
y <- dt(x, df)
data <- data.frame(x, y)

# Generate the data for the shaded area
x_fill <- seq(neg_t_critical, t_critical, length.out = 300)
y_fill <- dt(x_fill, df)
fill_data <- data.frame(x_fill, y_fill)

# Create the plot
ggplot(data, aes(x = x, y = y)) +
  geom_line() +
  geom_ribbon(data = fill_data, aes(x = x_fill, y = y_fill,  ymin = 0, ymax = y_fill), fill = "blue", alpha = 0.5) +
  geom_vline(xintercept = c(neg_t_critical, t_critical), linetype = "dashed", color = "red") +
  labs(title = paste("t-Distribution with df =", df, "and 95% Confidence Interval"),
       subtitle = "Shaded area represents 95% of the area under the curve",
       x = "t",
       y = "Density") +
  annotate("text", x = neg_t_critical, y = 0.1, label = paste("t =", round(neg_t_critical, 2)), color = "red", hjust = 1.2) +
  annotate("text", x = t_critical, y = 0.1, label = paste("t =", round(t_critical, 2)), color = "red", hjust = -0.2)+
  theme_minimal()
```

These critical values can be found using t-tables like the one below:

![](t-table.png)

For a 95% confidence interval, our Type I error rate is $\alpha = 0.05$. Since confidence intervals are two-tailed, we split this $\alpha$ in half, half in the left tail and half in the right tail. This means that we are looking for $t_{.025, df}$ or $t_{.975, df}$.

::: column-margin
**NOTE**: A **Type I** error is when we reject the null hypothesis when it is actually true. This is also known as a false positive.
:::

::: {.callout-note title="Exercise 1: t-distribution confidence intervals"}

The table below shows summary data for the first round of the 2023 Masters tournament for amateur golfers. The critical value is for a 90% confidence interval with 6 degrees of freedom.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
amateurs_round1 <- masters_2023 |> 
  filter(round == 1, tour == "Amateur")
x_bar <- amateurs_round1 |> 
  summarise(mean(score)) |> 
  pull()
std_dev <- amateurs_round1 |> 
  summarize(sd(score)) |> 
  pull()
n <- nrow(amateurs_round1)
t_cv <- qt(0.95, df = n - 1)
kable(data.frame("Amateurs Round 1", x_bar, std_dev, n, t_cv), col.names = c("Sample", "Sample Mean", "Sample Standard Deviation", "Sample Size", "Critical Value"))
```

Use the formula for creating a **confidence interval** using the t-distribution to calculate the upper and lower limits of a confidence interval for the true mean of amateur scoring using the amateurs in the first round as our sample. Use a 90% confidence interval ($\alpha = .1$). 

a. What is the **lower** bound of the confidence interval?

b. What is the **upper** bound of the confidence interval?

c. What is the **interpretation** of this confidence interval?

::: column-margin

**TIP**: When interpreting a confidence interval do **not** say "there is a 90% chance that the true mean is between the lower and upper bounds". Instead, say "we are 90% confident that the true mean is between the lower and upper bounds".

:::

::: column-margin

**TIP**: The t-table from earlier in the lesson will need to be used to find the critical value for the t-distribution for a 99% confidence interval with 6 degrees of freedom.
:::

Repeat this process with a 99% confidence interval ($\alpha = .01$).

d. What is the new **lower** bound of the confidence interval?

e. What is the new **upper** bound of the confidence interval?

f. Is this **99% confidence interval** larger, smaller, or the same as **90% confidence interval**?

g. When thinking about your anwer to **f**, what do you think could explain this?

:::

## z-interval for single means

A standard normal distribution (also known as a z-distribution) is used to calculate the confidence interval for a single mean if the sample size is large enough (greater than 30) or the population standard deviation is known. The first case is common as oftentimes samples are greater than 30. The second case is rare because it is uncommon to know the population standard deviation but not the population mean. 

The formula for the confidence interval for a single mean using the z-distribution is very similar to that of the t-distribution

::: column-margin

Click [here](https://www.scribbr.com/statistics/standard-normal-distribution/) for more information about the standard normal distribution.

:::

$CI = \bar{X} \pm Z_{\alpha/2} \times \frac{\sigma}{\sqrt{n}}$ 

Where $\bar{X}$ is once again the sample mean,
$Z_{\alpha/2}$ is the critical value for the standard normal distribution at the specified confidence level, 
${\sigma}$ is the population standard deviation, 
and $n$ is the sample size.

The reasoning behind why we can use the standard normal distribution when the sample is greater than 30 even if the population standard deviation is unknown is found in the [Central Limit Theorem](https://www.scribbr.com/statistics/central-limit-theorem/), which says that as the sample size increases, the sampling distribution of the sample mean approaches a normal distribution. This means that when the sample size is greater than 30 we can use the sample standard deviation to estimate the population standard deviation and create a confidence interval as seen below

$CI = \bar{X} \pm Z_{\alpha/2} \times \frac{S}{\sqrt{n}}$

Once again the critical value for the z-distribution is the value of $Z_{\alpha/2}$ such that the area under the standard normal distribution curve between $-Z_{\alpha/2}$ and $Z_{\alpha/2}$ is equal to the confidence level.

The critical values for the z-distribution can be found using a z-table such as the one below. All values in the table are the area under the curve to the left of the z-score. 

![](z-table.png)

::: {.callout-note title="Exercise 2: z-distribution confidence intervals"}

The table below shows summary data for the first round of the 2023 Masters Tournament for PGA professional golfers. The critical value is for a 95% confidence interval.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
pga_round1 <- masters_2023 |> 
  filter(round == 1, tour == "PGA")
x_bar <- pga_round1 |> 
  summarise(mean(score)) |> 
  pull()
sigma <- pga_round1 |> 
  summarise(sd(score)) |> 
  pull()
z_cv <- qnorm(.975)
kable(data.frame("PGA Round 1", x_bar, sigma, nrow(pga_round1), z_cv), col.names = c("Sample", "Sample Mean", "Standard Deviation Estimate", "Sample Size", "Critical Value"))
```

Use the formula for creating a confidence interval using the standard normal distribution to calculate the upper and lower limits of a confidence interval for the true mean of PGA professional scoring at Augusta using the PGA pros in the first round as our sample. Use a 95% confidence interval ($\alpha = .05$).

a. Why can we use the **standard normal distribution** to calculate this confidence interval?

b. What is the **confidence interval** for the true mean of scoring for PGA professionals at Augusta National?

c. What is the **interpretation** of this confidence interval?

:::

# Hypothesis Testing with Single Mean Confidence Intervals

Hypothesis testing is a method used to determine if a claim about a population parameter is true or not. In this section, we will perform the most common type of hypothesis test, a single mean test. The null hypothesis ($H_0$) is that the population mean is equal to a specific value, and the alternative hypothesis ($H_a$) is that the population mean is not equal to that value, greater than that value, or less than that value.

Null Hypothesis: $H_0: \mu = \mu_0$

Alternative Hypothesis Options: 

$H_a: \mu \neq \mu_0$ or

$H_a: \mu > \mu_0$ or

$H_a: \mu < \mu_0$


## Test Statistics

Like confidence intervals, we have two different tests for hypothesis testing for the population mean. Remember that if the population standard deviation is unknown and the sample size is less than 30, we use the t-distribution. If the population standard deviation is known or the sample size is greater than 30, we use the standard normal distribution.

Each of these distributions have their own tests, the t-test and the z-test. This means that we have different test statistics to calculate depending on the situation.

#### t-test

The t-test statistic is calculated using the formula:

$$t = \frac{\bar{x} - \mu_0}{\frac{s}{\sqrt{n}}}$$

where $\bar{x}$ is the sample mean, $\mu_0$ is the hypothesized population mean, $s$ is the sample standard deviation, and $n$ is the sample size.

#### z-test

The z-test statistic is calculated using the formula:

$$z = \frac{\bar{x} - \mu_0}{\frac{\sigma}{\sqrt{n}}}$$

where $\bar{x}$ is the sample mean, $\mu_0$ is the hypothesized population mean, $\sigma$ is the population standard deviation, and $n$ is the sample size.

## To Reject or Fail to Reject

There are two ways to make a decision about the null hypothesis. 

**Method 1**: **Critical values**, along with **test statistics**, can be used to determine if the **hypothesized population mean** is within the **confidence interval** for the true mean.

A **critical value** is a value that separates the rejection region from the non-rejection region. The rejection region is the area where the null hypothesis is rejected. The non-rejection region is the area where the null hypothesis is not rejected. The critical value is determined by the significance level ($\alpha$) and the degrees of freedom (if it is a t-test). The critical value is compared to the test statistic to determine if the null hypothesis should be rejected. If the test statistic is within the non-rejection region, the null hypothesis is not rejected. If the test statistic is within the rejection region, the null hypothesis is rejected and the alternative hypothesis is accepted.

Below is an example of using critical values and a test-statistic for a z-test with a 95% confidence level (two-sided). The critical value is 1.96. This means that if the test statistic is greater than 1.96 or less than -1.96, the null hypothesis is rejected. The blue represents the non-rejection region and the red the rejection region. Since the Test Statistic for this hypothetical example is 1.1 (less than 1.96 and greater than -1.96), we fail to reject the null hypothesis.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
z_values <- tibble(z = seq(-3, 3, .01),
                    y = dnorm(seq(-3, 3, .01)))

new_zy <- tibble(z = -3.00, y = 0) |> 
  bind_rows(z_values |> filter(z <= -1.96)) |> 
  add_row(z = -1.96, y = 0) 

non_rejection <- tibble(z = -1.96, y = 0) |> 
  bind_rows(z_values |> filter(z >= -1.96 & z <= 1.96)) |> 
  add_row(z = 1.96, y = 0)

upper_rejection <- tibble(z = 1.96, y = 0) |> 
  bind_rows(z_values |> filter(z >= 1.96)) |> 
  add_row(z = 3.00, y = 0)

ggplot(new_zy, aes(x = z, y = y))+
  geom_polygon(aes(x = z, y = y), fill = "red", alpha = .5)+
  geom_line()+
  geom_polygon(data = non_rejection, aes(x = z, y = y), fill = "blue", alpha = .5)+
  geom_line(data = non_rejection)+
  geom_polygon(data = upper_rejection, aes(x = z, y = y), fill = "red", alpha = .5)+
  geom_line(data = upper_rejection)+
  geom_vline(xintercept = -1.96, linetype = "dashed")+
  geom_vline(xintercept = 1.96, linetype = "dashed")+
  geom_vline(xintercept = 1.1, linetype = "solid")+
  geom_text(aes(x = -1.96, y = .1, label = "Critical Value: -1.96"), vjust = -2)+
  geom_text(aes(x = 1.96, y = .1, label = "Critical Value: 1.96"), vjust = -2)+ 
  geom_text(aes(x = 1, y = .1, label = "Test Statistic: 1.1"), vjust = -6)+
  labs(title = "Two-Sided z-test with 95% Confidence Level",
       subtitle = "Standard Normal Distribution",
       x = "Z",
       y = "Density")+
  theme_minimal()
  
```


This method corresponds directly to the related confidence intervals produced for the sample data.

If the hypothesized population mean is within the confidence interval, we fail to reject the null hypothesis. If the hypothesized population mean is not within the confidence interval, the null hypothesis is rejected and the alternative hypothesis is accepted.

::: column-margin

**Note**: We can say that there is significant evidence to accept the alternative hypothesis if the null hypothesis is rejected. However, it should never be said that we accept the null hypothesis. We can only fail to reject it.

:::

**Method 2**: The second method is to use a p-value. The p-value is the probability of observing a test statistic as extreme as the one calculated from the sample data given that the null hypothesis is true. The p-value is compared to the significance level ($\alpha$) to determine if the null hypothesis should be rejected. If the p-value is less than $\alpha$, the null hypothesis is rejected. If the p-value is greater than $\alpha$, the null hypothesis is not rejected.

::: column-margin
**NOTE**: Our **alternative hypothesis** determines whether we are looking for the probability that the test statistic is greater than or less than the observed value. 

- For a **two-sided test**, the p-value is the probability that the test statistic is greater than the observed value or less than the negative of the observed value. Find the area in one of the tails and double it.

- For a **left-tailed test** ($H_a: \mu < \mu_0$), the p-value is the probability that the test statistic is less than the observed value.

- For a **right-tailed test** ($H_a: \mu > \mu_0$), the p-value is the probability that the test statistic is greater than the observed value.
:::

For example, if the p-value for a single mean hypothesis test is 0.03 and the significance level is 0.05, the null hypothesis is rejected because the p-value is less than the significance level.

## Hypothesis testing example

Suppose we have a sample of data with the following values: 10, 20, 30, 40, 50, 60, 70, 80, 90, 100. We want to test if the true mean of the population is not equal to 50. Alpha is 0.05. Our hypotheses are as follows:

- Null Hypothesis ($H_0$): $\mu = 50$
- Alternative Hypothesis ($H_1$): $\mu \neq 50$

We can use the t-test to test this hypothesis. We start by finding the sample mean and sample standard deviation. The sample mean is 55 and the sample standard deviation is 30.2765. The degrees of freedom are 9. The critical value for a 95% two-sided confidence t-interval with 9 degrees of freedom is $\pm 2.262157$. 

The test statistic can be calculated as follows:

$$t = \frac{\bar{x} - \mu_0}{\frac{s}{\sqrt{n}}}$$
$$t = \frac{55 - 50}{\frac{30.2765}{\sqrt{10}}}$$
$$t = 0.522$$
Since the test statistic is between the two critical values, there is not enough evidence to reject the null hypothesis and conclude that the true mean is not equal to 50.

The p-value for this example could be calculated by finding the area
under the curve to the left of -0.522 and to the right of 0.522. The p-value would be the sum of these two areas. By looking at the t-table, it can be seen that the sum of these two areas would be well greater than .5, which is greater than .05. Therefore, the null hypothesis would not be rejected.

::: column-margin
**NOTE**: Since this is a two-sided test you could simply find the probability that the test statistic is greater than 0.522 and multiply by 2. This would give you the **p-value**.
:::

## Hypothesizing Par as the Population Mean

::: column-margin

Augusta National is breathtakingly beautiful, but if golfers get distracted by the scenic views, tall pines, bunkers, water, and azaleas may catch their balls. 

The 13th hole at Augusta National
<!-- ![](augusta_13.jpg) -->

<!-- Image Source: [Golf.com](https://golf.com/news/pros-on-new-masters-13th-hole/) -->

:::

In golf par is considered to be the number of strokes a good golfer is expected to take. The par for the course at Augusta National is 72. It is known that Augusta National is a tougher than usual course, but we would like to test if that is the case for different groups of golfers.

Our null hypothesis will generally be that the true mean of the group is equal to 72.


::: {.callout-note title="Exercise 3: t-test for single mean hypothesis testing"}

::: column-margin

Amateurs generally struggle in the Masters, but in 2023 Sam Bennett, a Texas A&M student, made the cut and finished 16th. However, due to his amateur status, he was not eligible to win money and missed out on $261,000. 

Sam Bennett
<!-- ![](sam_bennett.png) -->

<!-- Image Source: [Sportico](https://www.sportico.com/personalities/athletes/2024/sam-bennett-2023-masters-off-course-earnings-1234774995/) -->

:::

Amateurs, who are not yet professional golfers, are generally expected to score higher than professionals. We would like to test if the mean of amateur scoring is above par at Augusta National

a. What is the **null hypothesis** for this test?

b. What is the **alternative hypothesis** for this test?

Perform a single mean hypothesis test to see if the mean of amateur scoring is greater than 72 using the amateur round 1 score sample from earlier in the lesson. The summary of the sample is as follows:

```{r, echo=FALSE}
kable(data.frame("Amateurs Round 1", x_bar, std_dev, n), col.names = c("Sample", "Sample Mean", "Sample Standard Deviation", "Sample Size"))
```

c. What is the **critical value** for this test?

d. What is the **test statistic**?

e. What is the **p-value**?

f. Based on the p-value and the test statistic to critical value comparison, is there statistically significant evidence that the mean of amateur scoring at Augusta National is greater than 72?
:::


::: {.callout-note title="Exercise 4: z-test for single mean hypothesis testing"}

PGA professionals would generally average somewhere around par. We would like to test if the mean of PGA professional scoring is not equal to 72 at Augusta National.

a. What is the **null hypothesis** for this test?

b. What is the **alternative hypothesis** for this test?

Perform a single mean hypothesis test using the PGA Round 1 sample from earlier. The summary of that sample is displayed below.

```{r, echo=FALSE}
kable(data.frame("PGA Round 1", x_bar, std_dev, n), col.names = c("Sample", "Sample Mean", "Sample Standard Deviation", "Sample Size"))
```

c. What is the **critical value** for this test?

d. What is the **test statistic**?

e. What is the **p-value**?

f. What is your **conclusion**?

g. Explain your answer to part **d**.

:::

# More practice

If you would like more practice with confidence intervals and hypothesis testing, try the following exercises.

::: {.callout-note title="Challenge 1: Critical Values Knowledge Check"}

::: column-margin

```{r, include=FALSE}
liv_average <- masters_2023 |> 
  filter(tour == "LIV") |>
  summarise(mean(score)) |> 
  pull() |> 
  round(2)

pga_average <- masters_2023 |> 
  filter(tour == "PGA") |>
  summarise(mean(score)) |> 
  pull() |> 
  round(2)

amateur_average <- masters_2023 |>
  filter(tour == "Amateur") |>
  summarise(mean(score)) |>
  pull() |> 
  round(2)

senior_average <- masters_2023 |>
  filter(tour == "Senior") |>
  summarise(mean(score)) |>
  pull() |> 
  round(2)
```

**Fun fact**: In the 2023 Masters Tournament, the average score for LIV golfers was just slightly worse (`r liv_average`) than the average score for PGA golfers (`r pga_average`). However, the average score for amateurs (`r amateur_average`) and seniors (`r senior_average`) was significantly higher.

:::

Below is summary data from a sample of LIV golfers from round 3 of the 2023 Masters Tournament.

```{r, echo=FALSE}
liv_round3 <- masters_2023 |> 
  filter(round == 3, tour == "LIV")
kable(liv_round3 |> 
        summarise("LIV Round 3", mean(score), sd(score), n()), col.names = c("Sample", "Sample Mean", "Sample Standard Deviation", "Sample Size"))
```

a. What is the degrees of freedom for a single mean hypothesis test for the above sample of Augusta National scores?

b. Which of the following is the correct formula for the test statistic for a single mean hypothesis test for the above sample?

1. $t = \frac{\bar{X} - \mu_0}{\frac{S}{\sqrt{n}}}$
2. $z = \frac{\bar{X} - \mu_0}{\frac{\sigma}{\sqrt{n}}}$

c. Assume that the alternate hypothesis is that the true mean of scoring for LIV golfers at Augusta is greater than 72. Use the correct formula from part **b** to calculate the test statistic for the above sample manually. What is the value of the **test statistic**?

d. Assuming $\alpha = 0.05$, what is the **critical value** for the above sample?

e. Based on the test statistic and critical value, what is your **conclusion**?

:::

::: {.callout-note title="Challenge 2: P-Value Knowledge check"}

Answer the following questions based on the sample of Augusta National scores below.

```{r, echo=FALSE}
pro_round4 <- masters_2023 |> 
  filter(round == 4, tour == "PGA")
kable(pro_round4 |> 
        summarise("PGA Round 4", mean(score), sd(score), n()), col.names = c("Sample", "Sample Mean", "Sample Standard Deviation", "Sample Size"))
```

a. Use the proper method to test if the mean of the sample is equal to 72. What is the **p-value**?

b. Based on the p-value, what would be your **conclusion** if $\alpha = 0.01$?

c. Based on the p-value, what would be your **conclusion** if $\alpha = 0.05$?

d. Based on the p-value, what would be your **conclusion** if $\alpha = 0.10$?

e. Based on the p-value, what would be your **conclusion** if $\alpha = 0.20$?

f. What is wrong with doing multiple hypothesis tests with different $\alpha$ values that you choose after the fact?

:::

::: {.callout-note title="Challenge 3: Confidence Intervals Knowledge Check"}

Answer the following questions based on the 2 samples of Augusta National scores below.

```{r, echo=FALSE}
## Sample 1
amateur_round2 <- masters_2023 |> 
  filter(round == 2, tour == "Amateur")

## Sample 2
pga_rounds2_4 <- masters_2023 |> 
  filter(round %in% c(1, 2), tour == "PGA")

kable(bind_rows(amateur_round2 |> 
        summarise(s = "S1: Amateur Round 2", mean(score), sd(score), n()),
        pga_rounds2_4 |> 
          summarize(s = "S2: PGA Rounds 2 & 4",mean(score), sd(score), n())), col.names = c("Sample", "Sample Mean", "Standard Deviation Estimate", "Sample Size"))
```

a. Which of the above samples (sample 1 or sample 2) would you expect to have a **wider confidence interval** for the mean? Why?

b. How does the **sample size** affect the width of the confidence interval?

c. Using sample 2, if confidence intervals were made for confidence levels of 90%, 95%, and 99%, which confidence interval would be the **widest**?

d. What is the **relationship** between the confidence level and the width of the confidence interval?

:::

::: {.callout-note title="Challenge 4: z vs t (large sample size)"}

You have the following sample of Augusta National scores below. Answer the following questions based on the sample.

::: column-margin

```{r, include=FALSE}
scoring_1_2 <- masters_2023 |> 
  filter(round %in% c(1, 2)) |> 
  summarise(mean(score)) |> 
  pull() |> 
  round(2)

scoring_3_4 <- masters_2023 |> 
  filter(round %in% c(3, 4)) |> 
  summarise(mean(score)) |> 
  pull() |> 
  round(2)
```

**Think on it**: The average score for the first 2 rounds of the 2023 Masters Tournament was `r scoring_1_2`, while the average score for the last 2 rounds was `r scoring_3_4`. This is interesting because only the top players make it to the last 2 rounds, so you would expect the scores to be lower. What could have changed so that the best players are now scoring worse?

:::


```{r, echo=FALSE}
pga_rounds1_2 <- masters_2023 |> 
  filter(round %in% c(1, 2), tour == "PGA")

kable(pga_rounds1_2 |> 
        summarise("PGA Rounds 1 & 2", mean(score), sd(score), n()), col.names = c("Sample", "Sample Mean", "Sample Standard Deviation", "Sample Size"))

```

a. Create a **95% confidence interval** for the mean of the sample using a z-interval. What is the **confidence interval**?

b. Create a **95% confidence interval** for the mean of the sample using a t-interval. What is the **confidence interval**?

c. Which of the above confidence intervals is **wider**?

d. Based on your answer to the above question, would you say a t-distribution has **heavier** or **lighter** tailed than a z-distribution?

e. Is the difference in the **confidence intervals** in this problem likely to change a result in a hypothesis test? Why or why not?

:::
