{
  "hash": "2b9cd2a0a11966103a8009f470bb70e5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Tennis Sample Size\"\nauthor:\n  - name: Rodney X. Sturdivant, Ph.D.\n    email: Rodney_Sturdivant@baylor.edu\n    affiliation:\n      - id: baylor\n        name: Baylor University\ndate: July 1, 2024\nformat:\n  html:\n    # embed-resources: true\n    self-contained-math: true\n    grid:\n      margin-width: 350px\ntoc: true\ntoc-location: left\ndescription: Computing sample size for studies involving tennis\ncategories:\n  - Sample size\n  - Power\n  - Independent two sample t-test\n  - Independent two sample test of proportions\n  - Hypotheses testing \n  - Types of errors\neditor_options:\n  chunk_output_type: console\ncallout-icon: false\n---\n\n\n::: {.callout-note collapse=\"true\" title=\"Facilitation notes\" appearance=\"minimal\"}\n+ This module would be suitable for an in-class lab or take-home assignment in an introductory statistics course. \n\n+ It assumes a basic familiarity with the RStudio Environment has already been covered, but no prior programming experiences is expected.\n\n+ Students should be provided with the following data file (.csv) and Quarto document (.qmd) to produce tests/visualizations and write up their answers to each exercise. Their final deliverable is to turn in an .html document produced by \"Rendering\" the .qmd. \n  \n  + [data](wimbledon_featured_matches.csv)\n  + [Student Quarto template](tennis_student_template.qmd)\n\n+ [Posit Cloud](https://posit.cloud/) (via an Instructor account) or [Github classroom](https://classroom.github.com) are good options for disseminating files to students, but simply uploading files to your university's course management system works, too.\n:::\n\n# Welcome video\n\n<iframe width=\"560\" height=\"315\" src title=\"placeholder\">\n\n</iframe>\n\n# Introduction\n\nIn this module, you will compute the required sample size for studies involving tennis data, using data from Wimbledon 2023 matches to estimate required parameters. \n\n::: {.callout-note title=\"Learning Objectives\" appearance=\"minimal\"}\nBy the end of this module, you will be able to:\n\n-   Read (import) a dataset into your RStudio Environment\n\n-   Use R to obtain estimates for various parameters from existing data\n\n-   Compute sample size/power for studies involving:\n\n    - Independent two sample t-test\n    \n    - Independent two sample test of proportions\n    \n-   Understand basic principles for sample size and power analysis\n   \n:::\n\n::: column-margin\n\\\n\\\n\\\n\\\n\n**NOTE**: **R** is the name of the programming language itself and **RStudio** is a convenient interface. To throw even more lingo in, you may be accessing RStudio through a web-based version called **Posit Cloud**. But R is the programming language you are learning :) \n:::\n\n::: {.callout-caution collapse=\"true\" title=\"Research Questions\"}\n\nDuring this lab, you'll investigate the following research questions:\n\n+ What sample size is required for a study of the differences in running distances for tennis players on clay and grass courts\n+ What sample size is required for a study of the differences in percentage of points won on the first serve for tennis players on clay and grass courts\n\n:::\n\n# Getting started: Tennis data\n\nThe first step to any analysis in R is to **load necessary packages and data**. \n\n::: column-margin\nYou can think of **packages** like apps on your phone; they extend the functionality and give you access to many more features beyond what comes in the “base package”.\n:::\n\nRunning the following code will load the `tidyverse` package, and the `tennis` data we will be using in this lab.\n\n\n\n::: column-margin\n**TIP**: As you follow along in the lab, you should run each corresponding code chunk in your .qmd document. To \"Run\" a code chunk, you can press the green \"Play\" button in the top right corner of the code chunk in your .qmd. You can also place your cursor anywhere in the line(s) of code you want to run and press \"command + return\" (Mac) or \"Ctrl + Enter\" (Windows).\n:::\n\n::: column-margin\n**TIP**: Using a hashtag in R allows you to add comments to your code (in plain English). Data scientists often use comments to explain what each piece of the code is doing.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse) #loads package\nlibrary(DescTools)\nlibrary(effectsize)\nlibrary(pwr)\ntennis <- read_csv(\"wimbledon_featured_matches.csv\") #loads data\n```\n:::\n\n\nWe can use the `glimpse()` function to get a quick look (errr.. glimpse) at our `tennis` data. The `glimpse` code provides the number of observations (Rows) and the number of variables (Columns) in the dataset. The “Rows” and “Columns” are referred to as the **dimensions** of the dataset. It also shows us the names of the variables (`match_id`, `player1`, ..., `return_depth`) and the first few observations for each variable (e.g. the first match in the dataset has id \"1301\" and was Carlos Alcaraz playing Nicolas Jarry).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(tennis)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 7,284\nColumns: 46\n$ match_id           <chr> \"2023-wimbledon-1301\", \"2023-wimbledon-1301\", \"2023…\n$ player1            <chr> \"Carlos Alcaraz\", \"Carlos Alcaraz\", \"Carlos Alcaraz…\n$ player2            <chr> \"Nicolas Jarry\", \"Nicolas Jarry\", \"Nicolas Jarry\", …\n$ elapsed_time       <time> 00:00:00, 00:00:38, 00:01:01, 00:01:31, 00:02:21, …\n$ set_no             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ game_no            <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, …\n$ point_no           <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, …\n$ p1_sets            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ p2_sets            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ p1_games           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, …\n$ p2_games           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ p1_score           <chr> \"0\", \"0\", \"15\", \"15\", \"30\", \"40\", \"40\", \"AD\", \"40\",…\n$ p2_score           <chr> \"0\", \"15\", \"15\", \"30\", \"30\", \"30\", \"40\", \"40\", \"40\"…\n$ server             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, …\n$ serve_no           <dbl> 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, …\n$ point_victor       <dbl> 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, …\n$ p1_points_won      <dbl> 0, 1, 1, 2, 3, 3, 4, 4, 5, 6, 6, 7, 8, 8, 8, 9, 9, …\n$ p2_points_won      <dbl> 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 6, 7, 7, 8, …\n$ game_victor        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, …\n$ set_victor         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ p1_ace             <dbl> 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ p2_ace             <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, …\n$ p1_winner          <dbl> 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ p2_winner          <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, …\n$ winner_shot_type   <chr> \"0\", \"0\", \"0\", \"F\", \"0\", \"0\", \"0\", \"F\", \"0\", \"0\", \"…\n$ p1_double_fault    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ p2_double_fault    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ p1_unf_err         <dbl> 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ p2_unf_err         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, …\n$ p1_net_pt          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ p2_net_pt          <dbl> 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ p1_net_pt_won      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ p2_net_pt_won      <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ p1_break_pt        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ p2_break_pt        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ p1_break_pt_won    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ p2_break_pt_won    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ p1_break_pt_missed <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ p2_break_pt_missed <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ p1_distance_run    <dbl> 6.000, 5.253, 13.800, 51.108, 0.649, 5.291, 6.817, …\n$ p2_distance_run    <dbl> 7.840, 7.094, 19.808, 75.631, 0.813, 4.249, 17.821,…\n$ rally_count        <dbl> 2, 1, 4, 13, 1, 2, 1, 6, 7, 5, 1, 4, 4, 3, 1, 2, 1,…\n$ speed_mph          <dbl> 95, 118, 120, 130, 112, 97, 109, 105, 128, 110, 112…\n$ serve_width        <chr> \"BC\", \"B\", \"B\", \"BW\", \"W\", \"BW\", \"W\", \"B\", \"BC\", \"B…\n$ serve_depth        <chr> \"NCTL\", \"CTL\", \"NCTL\", \"CTL\", \"NCTL\", \"NCTL\", \"CTL\"…\n$ return_depth       <chr> \"ND\", \"ND\", \"D\", \"D\", NA, \"ND\", \"D\", \"ND\", \"D\", \"ND…\n```\n\n\n:::\n:::\n\n\n::: column-margin\n**ERROR?** Did you get a error message that says `could not find function \"glimpse\"`? This means you need to load the `tidyverse` package. You can do this by running the code `library(tidyverse)` from the previous code chunk. A shortcut is to hit the \"fast-forward\" button (next to the \"Play\" button in your code chunk), which will run all code chunks above your current one.\n:::\n\n\n\n## Tennis Data Overview\n\nBefore proceeding with any analysis, let's make sure we understand what information is contained for key variables (column) in our dataset.\n\nThe data set is from the 2023 Men's Singles Wimbledon Championships, perhaps the most important tennis tournament each year.\n\n::: {.callout-important}\n\n#### Basic Features of the Wimbledon 2023 data\n\n- Wimbledon is a single elimination tournament\n    - Round 1 begins with 128 players; 64 matches are played with the 64 winning players advancing to the second round.\n    - Subsequent rounds are played until two players reach the final; the winner of this final round is the Wimbledon Champion\n-   Our tennis data set includes all matches after the second round. \n-   The data provides information for every point played in the matches\n    - Each row represents a point\n    - Points are ordered within each match from the first to last point\n\n:::\n\n::: column-margin\nTotally new to Tennis? See this site: [INTRODUCTION TO TENNIS SCORING](https://www.sportingnews.com/us/tennis/news/tennis-scoring-explained-rules-system-points-terms/7uzp2evdhbd11obdd59p3p1cx)\n:::\n\n::: column-margin\nFor more information about Wimbledon: [Wimbledon Official Site](https://www.wimbledon.com/index.html)\n:::\n\n\n## Variable descriptions\n\nWe will actually only use a few columns for this module, but the full description of the data is provided.  Some variables have data for both players with columns with labels starting \"p1\" for player 1 and \"p2\" for player two.  We define these for player 1, but the definitions hold for the corresponding player 2 variables.\n\n<details>\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"vchwiftxdc\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#vchwiftxdc table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#vchwiftxdc thead, #vchwiftxdc tbody, #vchwiftxdc tfoot, #vchwiftxdc tr, #vchwiftxdc td, #vchwiftxdc th {\n  border-style: none;\n}\n\n#vchwiftxdc p {\n  margin: 0;\n  padding: 0;\n}\n\n#vchwiftxdc .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#vchwiftxdc .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#vchwiftxdc .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#vchwiftxdc .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#vchwiftxdc .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#vchwiftxdc .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#vchwiftxdc .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#vchwiftxdc .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#vchwiftxdc .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#vchwiftxdc .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#vchwiftxdc .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#vchwiftxdc .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#vchwiftxdc .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#vchwiftxdc .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#vchwiftxdc .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#vchwiftxdc .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#vchwiftxdc .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#vchwiftxdc .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#vchwiftxdc .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#vchwiftxdc .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#vchwiftxdc .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#vchwiftxdc .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#vchwiftxdc .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#vchwiftxdc .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#vchwiftxdc .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#vchwiftxdc .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#vchwiftxdc .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#vchwiftxdc .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#vchwiftxdc .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#vchwiftxdc .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#vchwiftxdc .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#vchwiftxdc .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#vchwiftxdc .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#vchwiftxdc .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#vchwiftxdc .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#vchwiftxdc .gt_left {\n  text-align: left;\n}\n\n#vchwiftxdc .gt_center {\n  text-align: center;\n}\n\n#vchwiftxdc .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#vchwiftxdc .gt_font_normal {\n  font-weight: normal;\n}\n\n#vchwiftxdc .gt_font_bold {\n  font-weight: bold;\n}\n\n#vchwiftxdc .gt_font_italic {\n  font-style: italic;\n}\n\n#vchwiftxdc .gt_super {\n  font-size: 65%;\n}\n\n#vchwiftxdc .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#vchwiftxdc .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#vchwiftxdc .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#vchwiftxdc .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#vchwiftxdc .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#vchwiftxdc .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#vchwiftxdc .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#vchwiftxdc .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#vchwiftxdc div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Variable\">Variable</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Definition\">Definition</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">match_id</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">match identification</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">player1</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">first and last name of the first player</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">player2</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">first and last name of the second player</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">elapsed_time</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">time elapsed since start of first point to start of current point (H:MM:SS)</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">set_no</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">set number in match</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">game_no</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">game number in set</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">point_no</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">point number in game</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">p1_sets</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">sets won by player 1</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">p1_games</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">games won by player 1 in current set</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">p1_score</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">player 1's score within current game</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">server</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">server of the point</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">serve_no</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">first or second serve</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">point_victor</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">winner of the point</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">p1_points_won</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">number of points won by player 1 in match</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">game_victor</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">a player won a game this point</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">set_victor</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">a player won a set this point</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">p1_ace</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">player 1 hit an untouchable winning serve</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">p1_winner</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">player 1 hit an untouchable winning shot</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">winner_shot_type</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">category of untouchable shot</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">p1_double_fault</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">player 1 missed both serves and lost the point</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">p1_unf_err</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">player 1 made an unforced error</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">p1_net_pt</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">player 1 made it to the net</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">p1_net_pt_won</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">player 1 won the point while at the net</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">p1_break_pt</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">player 1 has an opportunity to win a game player 2 is serving</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">p1_break_pt_won</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">player 1 won the game player 2 is serving</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">p1_break_pt_missed</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">player 1 missed an opportunity to win a game player 2 is serving</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">p1_distance_run</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">player 1's distance ran during point (meters)</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">rally_count</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">number of shots during the point</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">speed_mph</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">speed of serve (miles per hour; mph)</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">serve_width</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">direction of serve</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">serve_depth</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">depth of serve</td></tr>\n    <tr><td headers=\"Variable\" class=\"gt_row gt_left\">return_depth</td>\n<td headers=\"Definition\" class=\"gt_row gt_left\">depth of return</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n## Viewing your data\n\nYou saw that `glimpse()` is one way to get a quick look at your data. Often, you'll want to view your whole dataset. There are two ways to do this:\n\n::: column-margin :::\n\\\n**TIP:** Recall that RStudio is split into four quadrants: Source (upper left), **Environment** (upper right), **Console** (bottom left), and Files/Plots/Packages/Help/Viewer (bottom right)\n\n:::\n\n1. type `View(tennis)` in your **Console** and then click return/Enter on your keyboard. \n2. OR, in your **Environment** tab, double click the name of the dataset you want to view. \n\nThis will open up your data in a new viewer tab so that you can view it like a spreadsheet (like Google Sheets or Excel\\*). Once open, you can sort the data by clicking on a column. \n\n::: column-margin :::\n\\*Unlike Google Sheets or Excel, however, you won't be able to *edit* the data directly in the spreadsheet.\n:::\n\n::: {.callout-note  title=\"Exercise 1\"}\n\n`View` the `tennis` data and sort it appropriately to answer the following questions:\n\na.  We will be interested in the distances run.  Which variables in the data set contain this data?  What are example values (and units) for this data?  What are the smallest and largest values?\n\nb.  The second research question involves the percentage of points won on the first serve.  What variables provide information related to this question?  What type of variables are they and what are the possible values for each?\n\n:::\n\n::: column-margin\n\\\n**TIP:** Type your answers to each exercise in the .qmd document. \n\\\n\\\n\\\n\\\n\\\n:::\n::: column-margin :::\n**TIP**: When viewing the data, clicking on a column once will sort the data according to that variable in *ascending* order; clicking twice will sort in *descending* order.\n:::\n\n# Sample Size Overview\n\nWe will use statistical hypothesis testing to help address research questions using data (samples).  The tests involve the basic hypotheses:\n\n$H_0$: there is no effect/difference, the \"status quo\" (null hypothesis)\n\n$H_a$: there is an effect/difference (alternative hypothesis)\n\nWe are typically hoping to use the data to \"reject\" the null hypothesis and provide evidence that there is an effect.  As a simple example, suppose we develop a new training method to improve serving accuracy in tennis.  We will set up an experiment to compare percentage of first serves that are in (accurate) before and after the new training is applied.  The hypotheses would be:\n\n$H_0$: there is no difference in first serve percentage before and after the training  (null hypothesis)\n\n$H_a$: there is a difference (improvement) in first serve percentage after the training (alternative hypothesis)\n\nThe question before the experiment is how many samples should we collect in order to test the hypothesis?\n\n##  Why does sample size matter\n\nThere are several things that drive the need for sample size calculations.  One is resources.  Often it is costly - financially, time, difficulty in getting data - to conduct an experiment so we wish to do so efficiently, with the smallest sample possible.  The second is that we want a sample size that will ensure we can get meaningful results from our study.  The last thing anyone wants after spending time and money on research is for the results to be inconclusive.\n\n### Types of errors\n\nTwo types of errors can occur with a statistical hypotheses test.  \n\n- **Type I error**: the null hypothesis is true but we reject it.  \n\n- **Type II error**: the null hypothesis is false but we fail to reject it.\n\n::: {.callout-important}\n\nThe errors are a trade off - if we improve one, the other is worse.\n\n:::\n\n::: {.callout-note  title=\"Exercise 2\"}\n\nFor our proposed study of a method to improve first serve perentage:\n\na.  What would it mean to have a Type I error?\n\nb.  What would it mean to have a Type II error?\n\nc.  Is one error \"worse\" than the other in this case?  Explain.\n\n:::\n\n\n### Balancing the errors\n\nOur goal is to maintain reasonably small chances of both types of errors.  The Type I error is typically handled by specifying the probability we make such an error in our hypothesis testing procedure.  This probability is usually referred to as $\\alpha$ (\"alpha\") and set to a low value.  Most typically we use $\\alpha = 0.05$.  The Type II error, on the other hand, is NOT specified in the testing.  This is where sample size can play a role.\n\nReturning to our example, suppose we collect a sample and the first serve percentage without the training is 50\\% and after the training it is 75\\%.  Using an $\\alpha = 0.05$ value, however, we do not reject the null hypothesis.  We cannot conclude the sample provides evidence of improvement...even though it seems like a rather positive effect!  \n\nOur sample was from two games with 4 first serves each...a very small sample.  The problem is that with such a small sample we lack **power** to detect a difference even if it exists. **Power** is defined as:\n\n$$Power = 1 - \\beta$$\nWhere $\\beta$ is the Type II error rate.  Thus, we controlled Type I error but our Type II error rate may be too high!\n\nSmall samples lead to large uncertainty about the estimates.  Consider the 50\\% estimate for without training.  That was based on 2 of 4 successful serves.  However, if only one of the serves had been different (say one more success) that percentage would change by 25\\%!\n\n\n::: {.callout-important}\n\nA study that has too small of a sample size to detect a meaningful effect is said to be **under powered**.  The Type II error rate is very high.\n\n:::\n\nWe thus want a sample large enough that it will reject the null hypothesis when there is a true effect.  Generally speaking, resource constraints lead to trying to find the smallest sample size that has adequate power to do so.  There is little danger of getting \"too large\" a sample.  You might wonder, though, if resources permit why not just get a super large sample.  That would give very high power!\n\nThe problem with a very large sample is that there is power to detect very, very small effects.  For example, suppose we get a sample of millions of serves.  The result is 50\\% success without the training and 50.1\\% with the training.  The gigantic sample could lead to rejecting the null hypothesis, thus concluding there is evidence of difference due to the training.  \n\nThe sample size gives us great precision in these estimates...and, after, all technically they are different.  However, clearly the effect is not really a difference that any tennis play would care about enough to hire you as their trainer.\n\n::: {.callout-important}\n\nA study that has too large of a sample size to detect a meaningful effect is said to be **over powered**.  The Type II error rate is so low that meaningless effects are said to be significant.\n\n:::\n\n##  Factors impacting sample size (power)\n\nIn order to determine the sample size that gets us into the \"sweet spot\" (not in the sense of hitting a tennis ball) there are four factors that are important in some form for all \"power\" calculations:\n\n1.  The **sample size** (or **power**)\n\n- note that sometimes we use the **power** and compute sample size, and sometimes the reverse.  If **power** is used typical choices are $0.8$ or $0.9$ (meaning $\\beta = 0.2$ or $\\beta = 0.1$ Type II error rates).\n\n2.  Your chosen **Type I error rate**\n\n- Typically we use $\\alpha = 0.05$.\n\n3.  The amount of **variability** in the data.\n\n- Variability impacts the precision of estimates.\n\n4.  How **big of a difference** (or **how strong of an association**) you believe exists and is meaningful.\n\n\n\nItems 3 and 4 must be estimated in some fashion which is often a challenge for sample size calculation.  They are often combined and referred to as an **\"effect size\"**.  There are various measures of effect size in different settings with rules of thumb for what constitues small, medium, etc. effect sizes that are then used to compute the desired sample size.\n\n# Example 1: Power for two sample t-test\n\nRemember our first research question:\n\n::: {.callout-caution title=\"Research question\"}\n\nWhat sample size is required for a study of the differences in running distances for tennis players on clay and grass courts\n\n:::\n\nWe have data for distances run in meters.  Our sample will involve those distances on clay and grass courts.  The distances are a continuous variable so an appropiate test is two-sample t test.  The hypotheses for this test are:\n\n$$H_0: \\mu_{clay} = \\mu_{grass}$$\n\n$$H_a: \\mu_{clay} > \\mu_{grass}$$\n\nwhere $\\mu_{clay}$ is the true average distance run (in meters per point) on clay courts (and similar for $\\mu_{grass}$).  \n\n*Note we used \"greater than\" in the alternative hypothesis implying we believe the amount of running is greater on clay courts.  This reflects the general belief that the \"slower court\" leads to longer points as players are able to reach the ball more easily even if it is hit further from them.*\n\n## Estimating the Parameters\n\nWith the statistical method defined we are then ready to determine the parameter values we will use to perform our sample size computations.  We will compute sample size for a desired power, and set the first two parameters to typical values:\n\n1.  **Power** = $0.8$ \n\n2.  $\\alpha = 0.05$\n\nThe variability is often estimated from pilot or previous data, or using information from previous studies.  We will use our Wimbledon 2023 data.  We can compute the standard deviations (sd) for player one run distances and also for player two run distances:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsd(tennis$p1_distance_run)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 13.49286\n```\n\n\n:::\n\n```{.r .cell-code}\nsd(tennis$p2_distance_run)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 13.60765\n```\n\n\n:::\n:::\n\n\nBoth are similar and around 13.5 meters/point. So, we will choose this value:\n\n3.  sd = 13.5 meters/point (estimated variability)\n\nThe final value we need is the value of the difference in run distance that we would consider meaningful. The mean values for the run distances in the Wimbledon data are:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(tennis$p1_distance_run)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 14.00231\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(tennis$p2_distance_run)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 13.86924\n```\n\n\n:::\n:::\n\n\nBoth are around 14 meters/point.  What would represent a meaningful increase for the distance run on clay?\n\nOne tool that could help is to consider **effect size**.  Cohen (1988) offers some advice.  A metric known as Cohen's D is one measure and is defined:\n\n$$D = \\frac{\\mu_2 - \\mu_1}{sd}$$\nwhere the sd is of the difference in means.  If the average distance on clay increases by one standard deviation, then $D = 1$.  In other words, Cohen's D is the increase in terms of the standard deviation.  If $D = 0.5$ that would be an increase of half of a standard deviation,\n\nAn increase of 1 standard deviation (13.5 meters/point) seems large as it would nearly double the average run per point.\n\nThe R package \"effectsize\" contains a function to provide an interpretation of Cohen's D values.  We provide interpretation for the one standard deviation increase (13.5 meters/point) and for smaller increases of 0.5 and 0.25 standard deviations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninterpret_cohens_d(1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"large\"\n(Rules: cohen1988)\n```\n\n\n:::\n\n```{.r .cell-code}\ninterpret_cohens_d(0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"medium\"\n(Rules: cohen1988)\n```\n\n\n:::\n\n```{.r .cell-code}\ninterpret_cohens_d(0.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"small\"\n(Rules: cohen1988)\n```\n\n\n:::\n:::\n\n\nWe will opt for a \"medium\" effect size using the $D = 0.5$ value.  That would be an increase of one half of a standard deviation: $0.5 \\times 13.5 = 6.75$.\n\n4. **Difference in means (delta) = 6.75**.\n\n## Computing the Sample Size\n\nThe R command \"power.t.test\" computes the sample size (or power).  We compute sample size by leaving the parameter \"n\" as \"NULL\" (*note that NULL is the default so we did not need to explicitly specify in running the commmand*).  We must specify the power in this case; alternatively we could give a value of \"n\" and make the power NULL to compute power.\n\nOther values are shown below.  \n\n*Note that the type is \"two.sample\" because we are comparing two sample means.*  \n\n*The alternative is \"one.sided\" because we hypothesized and increase (>) in distance run on clay courts.  A $\\ne$ alternative hypothesis would be \"two.sided\".*\n\n\n::: {.cell}\n\n```{.r .cell-code}\npower.t.test(n = NULL, \n             delta = 6.76, \n             sd = 13.5, \n             sig.level = 0.05,\n             power = 0.8,\n             type = c(\"two.sample\"),\n             alternative = c(\"one.sided\")\n             )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Two-sample t test power calculation \n\n              n = 50.00462\n          delta = 6.76\n             sd = 13.5\n      sig.level = 0.05\n          power = 0.8\n    alternative = one.sided\n\nNOTE: n is number in *each* group\n```\n\n\n:::\n:::\n\n\nThe value returned is **n = 50.00462** which is the number per group (so points observed on each of the two court surfaces).  We **always round up** to ensure adequate power so we will need **n = 51 points per court surface** to conduct our study.\n\n::: {.callout-note  title=\"Exercise 3\"}\n\nIn the next exercises, we will examine how various parameters impact the required sample size.  Let's look first at the impact of **power**.  \n\na. Rerun the sample size calculation increasing the desired power to 0.9.  What sample size is required? \n\na. Rerun the sample size calculation decreasing the desired power to 0.7.  What sample size is required? \n\nc. Does increasing the power impact the required sample size?  Why?\n\n:::\n\n::: column-margin :::\n**TIP**: copy the command in our example and change the parameters as needed to complete each exercise.\n:::\n\n\n::: {.callout-note  title=\"Exercise 4\"}\n\n\nImpact of **\\alpha (alpha)**.  Return to a power of 0.8 for this exercise.\n\na. Rerun the sample size calculation decreasing the desired alpha to 0.01.  What sample size is required?\n\nb. Rerun the sample size calculation increasing the desired alpha to 0.1.  What sample size is required?  \n\nc.  How does changing the allowable Type I error impact the required sample size?  Why?\n\n:::\n\n::: {.callout-note  title=\"Exercise 5\"}\n\nImpact of variability, **sd**.  Return to a power of 0.8 and  alpha of 0.05\n\na.  Increase the sd to 15.  What sample size is required?  \n\nb.  Increase the sd to 10.  What sample size is required?\n\nc.  How does the estimated variability in the data impact the required sample size?  Why?\n\n\n:::\n\n::: {.callout-note  title=\"Exercise 6\"}\n\nImpact of size of the difference, **delta**.  Return to a power of 0.8, alpha of 0.05, and sd of 13.5.  \n\na.  What value of delta leads to a small effect of D = 0.25 standard deviation increase?\n\nb.  What value of delta produces a large effect of D = 1 sd increase?\n\nc.  Find the sample size for the delta values computed in a and b.\n\nd.  How does the effect size impact the required sample size?  Why?\n\n:::\n\n::: {.callout-note  title=\"Exercise 7\"}\n\nComputing **power** instead of sample size.  Use the original values in the example (delta = 6.75, sd = 13.5, alpha = 0.05).  We computed a sample size of 51 to achieve power of 0.8 in the example.  \n\na.  Modify the command by setting power to \"NULL\" and the sample size to n = 51.  Does the computed power exceed 0.8?   \n\nb.  What is the power if n = 50 (recall we rounded up)?\n\n:::\n\n\n# Example 2: Power for two sample test of proportions\n\nNow let's consider our second research question:\n\n::: {.callout-caution title=\"Research question\"}\n\nWhat sample size is required for a study of the differences in percentage of points won on the first serve for tennis players on clay and grass courts?\n\n:::\n\nWe are now considering comparison of proportions (of points won when hitting a first serve into the court).  Our sample will involve those proportions on clay and grass courts.  The appropiate test is thus the two-sample test of proportions.  The hypotheses for this test are:\n\n$$H_0: p_{clay} = p_{grass}$$\n$$H_a: p_{clay} < p_{grass}$$\n\nwhere p is the true proportion of first serve points won on the given surface.\n\nNotice that we again chose a one sided alternative, but this time with the proportion on clay courts less than on grass.  The slower clay courts are thought to make it easier to return hard first serves.  Again, if we did not have prior knowledge about the impact of the surface we would use a $\\ne$ alternative here.\n\n## Estimating the Parameters\n\nWe will again compute sample size for a desired power, and set the first two parameters to typical values:\n\n1.  **Power** = $0.8$ \n\n2.  $\\alpha = 0.05$\n\nThe third parameter, estimate of variability, is not needed for the two sample proportions test.  The reason is that the variance for a proportion is actually a function of the proportion.  This comes from the variance for a binary (0 or 1) variable which is modeled using the Binomial (Bernoulli) distribution.  If the true proportion is p, then the variance is:\n\n$$p \\times (1-p)$$\n\nSo, once we provide a hypothesized value for p, then the variance can be computed!\n\nThe fourth parameter is again the difference we would consider meaningful.  We can use our data to get an estimate for the proportion of points won on grass for a first serve. \n\nWe first get the percentage for player one.  The \"filter\" function allows us to select only first serve data (\"serve_no ==1\") when player one is serving (\"server == 1\").  We then obtain the table with percentages of which player won the point.\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1serve1 <- tennis |> filter(serve_no == 1 & server == 1)\nPercTable(p1serve1$point_victor)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               \n    freq   perc\n               \n1  1'728  76.6%\n2    529  23.4%\n```\n\n\n:::\n:::\n\n\nSince player 1 is the server in this reduced data set, we see that the server wins 76.6\\% of the points.\n\nWe can repeat this for player two (below) and find a similar percentage of 74.3\\%.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np2serve1 <- tennis |> filter(serve_no == 1 & server == 2)\nPercTable(p2serve1$point_victor)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               \n    freq   perc\n               \n1    616  25.7%\n2  1'784  74.3%\n```\n\n\n:::\n:::\n\n\nWe select a reasonable percentage then for Wimbledon (grass) of 75\\%.  The question is what would be a noteworthy difference in winning percentage on clay.\n\nWe can again consider effect size, and R package \"pwr\" provides a function \"ES.h\" that computes an effect size based on two proportions known as Cohen's H (Cohen, 1988).  The rules of thumb for this value are the same as for Cohen's D, so we can again use the \"interpret_cohens_d\" function once we obtain a value.\n\nLet's see what the effect size is if the percentage won on clay is only 50\\%:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprop_effect <- ES.h(0.75, 0.5)\nprop_effect\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5235988\n```\n\n\n:::\n\n```{.r .cell-code}\ninterpret_cohens_d(prop_effect)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"medium\"\n(Rules: cohen1988)\n```\n\n\n:::\n:::\n\n\nThe result is a \"medium\" effect, but practically that seems like an unlikely change.  Even though clay might reduce the serve advantage, it still probably exists.  Let's consider reducing the advantage to 65\\%:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprop_effect <- ES.h(0.75, 0.65)\nprop_effect\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.2189061\n```\n\n\n:::\n\n```{.r .cell-code}\ninterpret_cohens_d(prop_effect)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"small\"\n(Rules: cohen1988)\n```\n\n\n:::\n:::\n\n\nThis is a small effect size, but practically certainly meaningful so we will use this in our calculations:\n\n4. **Difference in proportions**:  0.1 (from 0.75 to 0.65)\n\n## Computing the Sample Size\n\nThe command for proportions is \"power.prop.test\".  For difference in proportions, we actually input the two proportions rather than the delta.  As we will see in the exercises, this matters as the estimate of the variance is based on the hypothesized proportion.  The rest of the options are similar to those for the two sample t-test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npower.prop.test(n = NULL, \n                p1 = 0.75, \n                p2 = 0.65, \n                sig.level = 0.05, \n                power = 0.8,\n                alternative = \"one.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Two-sample comparison of proportions power calculation \n\n              n = 258.619\n             p1 = 0.75\n             p2 = 0.65\n      sig.level = 0.05\n          power = 0.8\n    alternative = one.sided\n\nNOTE: n is number in *each* group\n```\n\n\n:::\n:::\n\n\nThe value returned is **n = 258.619** per group so we will need **n = 259 points per court surface** to conduct this second study.\n\n::: {.callout-note  title=\"Exercise 8\"}\n\nAs mentioned in the example, the hypothesized proportion impacts the estimate of the variance.  We explore this impact in this exercise. \n\na.  Modify the sample size calculation so that the effect is still 0.1 but based on 70\\% for p1 and 60\\% for p2.  What is the resulting sample size?  How does this compare to the sample size in the example using 75\\% and 60\\%?  \n\nb.  The variance estimate is related to the value $p \\times (1-p)$.  What is this value if p = 0.75?  What is the value when p = 0.7?  Which variance is larger?\n\nc.  Based on the results from part b, and from your exploration of the role of variability in sample size calculations for the two sample t-test, explain the change in sample size in part a.\n\n:::\n\n::: {.callout-note  title=\"Exercise 9\"}\n\nFormulate an additional question that involves two sample means using variables available in the data set and compute sample size in similar fashion to example 1.\n\n:::\n\n::: {.callout-note  title=\"Exercise 10\"}\n\nFormulate an additional question that involves two sample proportions using variables available in the data set and compute sample size in similar fashion to example 2.\n\n:::\n\n# REFERENCES\n\nCohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}