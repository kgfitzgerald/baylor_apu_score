{
  "hash": "67a7c6e8daad7cd792a005d5246b0c10",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"PGA - Scoring Average Confidence Intervals\"\nauthor:\n  - name: Jonathan Lieb\n    email: jonathan_lieb1@baylor.edu\n    affiliation:\n      - id: bay\n        name: Baylor University\ndate: January 25, 2025\nformat:\n  html:\n    grid:\n      margin-width: 350px\ntoc: true\ntoc-location: left\ndescription: Exploring Single Mean Confidence Intervals with Golf Data\ncategories:\n  - Single Mean Confidence Intervals\n  - Single Mean Hypothesis Testing\neditor_options:\n  chunk_output_type: console\ncallout-icon: false\n# embed-resources: true\n---\n\n\n\n\n::: {.callout-note collapse=\"true\" title=\"Facilitation notes\" appearance=\"minimal\"}\n+ This module would be suitable for an in-class lab or take-home assignment in an introductory statistics course. \n\n+ It assumes a basic familiarity with the RStudio Environment and R programming language.\n\n+ Students should be provided with the following data file (.csv) and Quarto document (.qmd) to produce visualizations and write up their answers to each exercise. Their final deliverable is to turn in an .html document produced by \"Rendering\" the .qmd. \n  \n  + [Data](masters_2023.csv)\n  + [Student Quarto template](student_template.qmd)\n\n+ The data for this module is derived largely from the [ESPN website](https://www.espn.com/golf/leaderboard/_/tournamentId/401465508). However, the tours were manually added to the data based on the what they played on in 2023 at the time of the Masters.\n:::\n\n# Welcome video\n\n<iframe width=\"560\" height=\"315\" src title=\"placeholder\">\n\n</iframe>\n\n# Introduction\n\nIn this module, you will be exploring the concepts of single mean confidence intervals and single mean hypothesis tests using data from the 2023 Masters tournament. The Masters is considered to be one of the greatest and most selective tournaments in the world of golf. Only the best current players or previous winners are allowed in. The winner of the Masters gets to wear the famed \"Green Jacket\" and return to play any year they would like at the Masters. The course the Masters is played at, Augusta National, is one of the most beautiful and challenging courses in the world. The course is known for its fast greens and tight fairways. The Masters is the first major of the year and is played in early April. The tournament is played over four days. After 2 days, the top 50 players and ties make the cut and play the final two days. \n\n::: column-margin\n![Master's Leaderboard](Augusta_Leaderboard.jpg)\n\nImage Source: <a href=\"https://commons.wikimedia.org/wiki/File:Augusta_National_Leaderboard_(17071936729).jpg\">Ryan Schreiber</a>, <a href=\"https://creativecommons.org/licenses/by/2.0\">CC BY 2.0</a>, via Wikimedia Commons\n:::\n\n::: column-margin\n\nView the course at Augusta National [here](https://www.masters.com/en_US/course/index.html)\n\n:::\n\n\nAs mentioned before, only the best players and previous winners can compete in the tournament, With that being said, the Masters is one of the few tournaments that players from the newly created LIV Golf tour can play in, although they are mostly qualifying because of their past performances at the Masters before they joined LIV Golf. This leads to a mixture of regular PGA Tour professionals, LIV golfers, Amateurs, and Seniors playing in the Masters in 2023. \n\n\nThe focus for this module is confidence intervals and hypothesis testing for the true mean scores for different groups of players at Augusta National. \n\n::: {.callout-note title=\"Learning Objectives\" appearance=\"minimal\"}\nBy the end of this lesson, you will be able to:\n\n-   Read (import) a dataset into your RStudio Environment\n\n-   Make single mean confidence intervals\n\n-   Perform a hypothesis test for a single mean\n:::\n\n::: column-margin\n\\\n\\\n\\\n\\\n\n**NOTE**: **R** is the name of the programming language you are using and **RStudio** is a **IDE** (Integrated Development Environment). You may be accessing RStudio through a web-based version called **Posit Cloud**, but **R** is still the language. \n:::\n\n\n::: {.callout-caution collapse=\"true\" title=\"Research Questions\"}\n\nDuring this module, you'll investigate the following research questions:\n\n+ What are the confidence intervals for true scoring for different groups of players at the 2023 Masters Tournament?\n+ Is the true mean for different groups of players at The 2023 Masters different than par?\n+ Is the true mean of amateur scoring greater than par at Augusta National?\n+ How do sample size and confidence level affect the width of a confidence interval?\n\n:::\n\n# Getting started: 2023 Masters Data\n\nThe first step to any analysis in R is to **load necessary packages and data**. \n\n::: column-margin\nYou can think of **packages** like apps on your phone; they extend the functionality and give you access to many more features beyond what comes in the “base package”.\n:::\n\nRunning the following code will load the `tidyverse` and `BSDA` packages and the `masters_2023` data we will be using in this module.\n\n::: column-margin\n**TIP**: As you follow along in the module, you should run each corresponding code chunk in your .qmd document. To \"Run\" a code chunk, you can press the green \"Play\" button in the top right corner of the code chunk in your .qmd. You can also place your cursor anywhere in the line(s) of code you want to run and press \"command + return\" (Mac) or \"Ctrl + Enter\" (Windows).\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(BSDA)\n\nmasters_2023 <- read_csv(\"masters_2023.csv\")\n```\n:::\n\n\n\n\nWe can use the `glimpse()` function to get a quick look at our `masters_2023` data. The `glimpse` code provides the number of observations (Rows) and the number of variables (Columns) in the dataset. The “Rows” and “Columns” are referred to as the **dimensions** of the dataset. It also shows us the names of the variables and the first few observations for each variable. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(masters_2023)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 277\nColumns: 4\n$ player <chr> \"Jon Rahm\", \"Jon Rahm\", \"Jon Rahm\", \"Jon Rahm\", \"Phil Mickelson…\n$ round  <dbl> 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, …\n$ score  <dbl> 65, 69, 73, 69, 71, 69, 75, 65, 65, 67, 73, 75, 69, 70, 76, 66,…\n$ tour   <chr> \"PGA\", \"PGA\", \"PGA\", \"PGA\", \"LIV\", \"LIV\", \"LIV\", \"LIV\", \"LIV\", …\n```\n\n\n:::\n:::\n\n\n\n\nAnother useful function to get a quick look at the data is the `head()` function. This function shows the first few rows of the dataset. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(masters_2023)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n  player         round score tour \n  <chr>          <dbl> <dbl> <chr>\n1 Jon Rahm           1    65 PGA  \n2 Jon Rahm           2    69 PGA  \n3 Jon Rahm           3    73 PGA  \n4 Jon Rahm           4    69 PGA  \n5 Phil Mickelson     1    71 LIV  \n6 Phil Mickelson     2    69 LIV  \n```\n\n\n:::\n:::\n\n\n\n\n\n::: {.callout-note  title=\"Exercise 1: Data Structure\"}\n\na. How many **observations (rows)** are in this data?\n\nb. How many **variables (columns)** are in the data?\n\nc. Which **variable** will be used for computing a single mean confidence interval?\n\n:::\n\n::: column-margin\n\\\n**TIP:** Type your answers to each exercise in the .qmd document. \n\\\n:::\n\n## Terms to know\n\nBefore proceeding with the analysis, let's make sure we know some important golf terminology that will help us master this module.\n\n#### Golf Terminology\n-   **Par** in golf is the amount of strokes that a good golfer is expected to take to get the ball in the hole.\n    - Each **hole** in golf has its own **par**. There are **par 3** holes, **par 4** holes, and **par 5** holes. \n    - There are 18 holes on a golf course and the **pars** of each of these holes sums to **par for the course**, also known the **course par**. \n-   A **round** in golf is when a golfer plays the full set of 18 holes on the course.\n    - In most professional golf tournaments, all golfers play **2 rounds**, the best golfers are selected and those golfers play 2 more rounds for a total of **4 rounds**.\n\n\n::: {.callout-important}\n\n#### Types of Golf Tours\n- In golf there are a few **tours**, better thought of as leagues, that golfers regularly compete in\n\n     -  The **PGA Tour**, or \"Professional Golf Association Tour\", has long been considered the preeminant golfing tour, hosting most tournaments and containing the most skilled members.\n     - The **LIV Golf** tour is a Saudi-backed alternative to the PGA Tour that began playing tournaments in 2022. **LIV** is the Roman numeral for 54 and is related to the fact that **LIV** tournaments only allow 54 players and only play 54 holes, compared to the normal PGA Tour 72 holes.\n     - The **PGA Tour Champions** is a branch off of the PGA tour for players 50 or older. It used to be called the \"Senior PGA Tour\" until 2003, when it began being called the **Champions** tour\n     - An **amateur** is a golfer who is not yet a professional. They are not allowed to win money in professional golf tournaments. Most **amateurs** are college golfers. \n\n:::\n\n::: column-margin\n\nPGA vs. LIV\n\nClick [here](https://www.si.com/golf/news/timeline-liv-golf-how-pga-tour-adapted) to read about LIV golf's founding and its continued impact on the PGA tour.\n\n:::\n\n## Variable descriptions\n\nThe `masters_2023` data you'll be analyzing in this module provides scores for each round by each golfer in the 2023 Masters. The data includes the names of golfers, the round, their scores, and their tour.\n\n<details>\n<summary><b>Variable Descriptions</b></summary>\n\n| Variable | Description |\n|----|----------------------------|\n| `player` | Golfer's name |\n| `round` | Round of the tournament |\n| `score` | Score for the 18-hole course |\n| `tour` | The tour the player generally competes on |\n\n\n# Single Mean Confidence Intervals\n\nSingle mean confidence intervals give a range of numbers that we can feel confident that the true population mean falls between. \nIn the most accurate sense, a single mean confidence interval is a range of values that,\nif we were to take many samples and calculate the confidence interval for each sample,\na certain percentage of those intervals would contain the true population mean.\nBecause of what a single mean confidence interval is, it is innaccurate to say that there is \na 95% chance (if we were constructing a 95% confidence interval) that the true mean falls within the the confidence interval. The true mean is a fixed value,\nso it either falls within the interval or it does not. The 95% confidence level refers to the long-run proportion of confidence intervals\nthat will contain the true mean if we were to take many samples.This can lead to difficulties interpreting\nthese ranges in practice though. An accurate interpretation of a single mean confidence interval will often follow the structure below:\n\n**We are *(insert confidence level)* confident that the true *(insert variable)* mean for *(insert population group)* is between *(insert lower bound)* and *(insert upper bound)*.**\n\n\nFor example:\n\n  **We are 95% confident that the true scoring average for LIV golfers at Augusta National is between 70.1 and 73.3.**\n  \n\nThere are two different ways of calculating the confidence interval for a single mean. How we\ndetermine which of the two methods to use is based on the sample size and whether\nor not the population standard deviation is known. \n\n## t-interval for single means\n\nA t-distribution is used for calculating a single mean confidence interval if the sample size is small (rule of thumb: less than 30) and the population standard deviation is unknown. \n\nThe formula for calculating a CI using this method is shown below:\n$$CI = \\bar{X} \\pm t_{\\alpha/2, df} \\times \\frac{S}{\\sqrt{n}}$$\n\n::: column-margin\n\nClick [here](https://www.scribbr.com/statistics/t-distribution/) to learn more about the t-distribution and play around with t-distribution graphs.\n\n:::\n\nWhere $\\bar{X}$ is the sample mean,\n\n$t_{\\alpha/2, df}$ is the critical value for the t-distribution\nwith $df = n-1$,\n\n$S$ is the sample standard deviation,\n\nand $n$ is the sample size.\n\n::: column-margin\n\n**NOTE**: The t-distribution changes based on the degrees of freedom, approaching the normal distribution as the degrees of freedom increase.\n\n:::\n\nThe critical value for the t-distribution is determined by the confidence level and the degrees of freedom. This is calculated by finding the value of $t_{\\alpha/2, df}$ such that the area under the t-distribution curve (with that specific degrees of freedom) between $-t_{\\alpha/2, df}$ and $t_{\\alpha/2, df}$ is equal to the confidence level. \n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n\n\n::: column-margin\n\n**NOTE**: Using R to calculate the critical value for the t-distribution saves time and adds accuracy compared to using a t-table.\n\n:::\n\n**R** can easily calculate the critical value for the t-distribution using the `qt()` function. \n\nThe `qt()` function takes two arguments: the first is the confidence level, and the second is the degrees of freedom. The example below shows how to calculate the t-value for a 95% confidence level with 10 degrees of freedom.\n\nNote that the 95% confidence interval has $\\alpha = .05$ and $\\alpha / 2 =  .025$ so we need to use `qt(.975, df= 10)` or `qt(.025, df = 10)` to find the critical values.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqt(0.975, df = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.228139\n```\n\n\n:::\n:::\n\n\n\n\n::: {.callout-note collapse=\"true\" title=\"Example: t-distribution confidence intervals\"}\nWe would like to make a 90% confidence interval for the true mean of scoring for Jon Rahm at the Masters. We can pull his scores and put them in a vector with following code. We will also set the sample size (n) to the amount of observations in the sample.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\njon_rahm <- masters_2023 |> \n  filter(player == \"Jon Rahm\") |> \n  pull(score)\n\nn <- length(jon_rahm)\n```\n:::\n\n\n\n\nWe start by calculating the the sample mean ($\\bar{x}$).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx_bar <- mean(jon_rahm)\n```\n:::\n\n\n\n\n\nNext we calculate the sample standard deviation ($s$).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- sd(jon_rahm)\n```\n:::\n\n\n\n\n\nOur next step is to find the critical value for a 90% confidence interval with 3 degrees of freedom ($t_{\\alpha/2, df}$). We'll use the `qt` function from **R** to do this. Note that we use .95 as the first argument because alpha is .1 and half of our error should be in each end.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncv <- qt(.95, 3)\n```\n:::\n\n\n\n\n\nLastly we will use the confidence interval formula to find the bounds of our 90% confidence interval.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlower_confidence_boundary <- x_bar - cv * (s/n)\nupper_confidence_boundary <- x_bar + cv * (s/n)\npaste0(\"90% confidence interval: (\", lower_confidence_boundary, \", \", upper_confidence_boundary, \")\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"90% confidence interval: (67.078486801804, 70.921513198196)\"\n```\n\n\n:::\n:::\n\n\n\n\n\nFinally we can interpret the confidence interval and say that we are 95% confident that the true mean of Jon Rahm's scores at Augusta National is between 67.1 and 70.9. \n\n:::\n\n\n::: {.callout-note title=\"Exercise 2: t-distribution confidence intervals\"}\n\n:::column-margin\n**TIP**: Values and objects can be stored in variables in R. For example, `x <- 5` stores the value 5 in the variable `x`.\n\n**TIP**: The **pipe operator** is a powerful tool in R that allows you to chain functions together. It is denoted by `|>` and is used to pass the output of one function to the input of another function.\n\n**TIP**: The `pull()` function is used to extract a single column from a data frame as a vector.\n\n**TIP**: The `nrow()` function is used to calculate the number of rows in a data frame.\n:::\n\nRun the code below to create the proper subset of the data for this exercise and calculate the sample mean and sample standard deviation.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\namateurs_round1 <- masters_2023 |> \n  filter(round == 1, tour == \"Amateur\")\nx_bar <- amateurs_round1 |> \n  summarise(mean(score)) |> \n  pull()\nstd_dev <- amateurs_round1 |> \n  summarize(sd(score)) |> \n  pull()\nn <- nrow(amateurs_round1)\nt_cv <- qt(0.95, df = n - 1)\n```\n:::\n\n\n\n\nUse the formula for creating a **confidence interval** using the t-distribution to calculate the upper and lower limits of a confidence interval for the true mean of amateur scoring using the amateurs in the first round as our sample. Use a 90% confidence interval ($\\alpha = .1$). \n\na. What is the **lower** bound of the confidence interval?\n\nb. What is the **upper** bound of the confidence interval?\n\nc. What is the **interpretation** of this confidence interval?\n\n::: column-margin\n\n**TIP**: When interpreting a confidence interval do **not** say \"there is a 90% chance that the true mean is between the lower and upper bounds\". Instead, say \"we are 90% confident that the true mean is between the lower and upper bounds\".\n\n:::\n\n::: column-margin\n\n**TIP**: Only the `t_cv` variable needs to be changed to recompute with the new confidence interval. Use `qt(0.995, df = n - 1)` to calculate the critical value for the new 99% confidence interval.\n:::\n\nRepeat this process with a 99% confidence interval ($\\alpha = .01$).\n\nd. What is the new **lower** bound of the confidence interval?\n\ne. What is the new **upper** bound of the confidence interval?\n\nf. Is this **99% confidence interval** larger, smaller, or the same as **90% confidence interval**?\n\ng. When thinking about your anwer to **f**, what do you think could explain this?\n\n:::\n\n## z-interval for single means\n\nA standard normal distribution (also known as a z-distribution) is used to calculate the confidence interval for a single mean if the sample size is large enough (greater than 30) or the population standard deviation is known. The first case is common as oftentimes samples are greater than 30. The second case is rare because it is uncommon to know the population standard deviation but not the population mean. \n\nThe formula for the confidence interval for a single mean using the z-distribution is very similar to that of the t-distribution\n\n::: column-margin\n\nClick [here](https://www.scribbr.com/statistics/standard-normal-distribution/) for more information about the standard normal distribution.\n\n:::\n\n$CI = \\bar{X} \\pm Z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}$ \n\nWhere $\\bar{X}$ is once again the sample mean,\n$Z_{\\alpha/2}$ is the critical value for the standard normal distribution at the specified confidence level, \n${\\sigma}$ is the population standard deviation, \nand $n$ is the sample size.\n\nThe reasoning behind why we can use the standard normal distribution when the sample is greater than 30 even if the population standard deviation is unknown is found in the [Central Limit Theorem](https://www.scribbr.com/statistics/central-limit-theorem/), which says that as the sample size increases, the sampling distribution of the sample mean approaches a normal distribution. This means that when the sample size is greater than 30 we can use the sample standard deviation to estimate the population standard deviation and create a confidence interval as seen below\n\n$CI = \\bar{X} \\pm Z_{\\alpha/2} \\times \\frac{S}{\\sqrt{n}}$\n\nOnce again the critical value for the z-distribution is the value of $Z_{\\alpha/2}$ such that the area under the standard normal distribution curve between $-Z_{\\alpha/2}$ and $Z_{\\alpha/2}$ is equal to the confidence level.\n\n**R** can compute the z-value for you using the `qnorm()` function. The `qnorm()` function takes in the probability and returns the z-value that corresponds to that probability. For example, `qnorm(.975)` will return the z-value that corresponds to the 97.5th percentile of the standard normal distribution. No degrees of freedom are needed.\n\nThe code below calculates the critical values for the z-distribution for a 95% confidence interval.  \n(Note that .975 is used for a 95% confidence interval because $\\alpha = .05$ and since the confidence interval is two sided we need half of the error each side so $\\alpha / 2  = .025$, which means we want to use `qnorm(.975)` or `qnorm(.025)`)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqnorm(.975)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.959964\n```\n\n\n:::\n\n```{.r .cell-code}\nqnorm(.025)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -1.959964\n```\n\n\n:::\n:::\n\n\n\n\n::: {.callout-note collapse=\"true\" title=\"Example: z-distribution confidence intervals\"}\nWe would like to make a 98% confidence interval for the true mean of scoring for PGA Tour golfers based off \nof a sample from the third round. This sample can be created with the following code.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npga_round3_scores <- masters_2023 |> \n  filter(tour == \"PGA\", round == 3) |> \n  pull(score)\n```\n:::\n\n\n\n\nWe can check the size of our sample with the following code.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npga_round3_n <- length(pga_round3_scores)\npga_round3_n\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 39\n```\n\n\n:::\n:::\n\n\n\n\nThat's 39 observations we have in our sample, which means we can use the z-distribution.\n\nWe start by calculating the the sample mean ($\\bar{x}$). `R` can do this very easily as seen below\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npga_round3_mean <- mean(pga_round3_scores)\n```\n:::\n\n\n\n\n\nNext we calculate the sample standard deviation ($s$), which is our estimate for $\\sigma$. Once again, `R` can do this quickly.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npga_round3_sd <- sd(pga_round3_scores)\n```\n:::\n\n\n\n\nOur next step is to find the critical value for a 98% confidence interval for a \nz-distribution ($Z_{\\alpha/2}$). We can use `qnorm` to do this.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nz_cv <- qnorm(.99)\n```\n:::\n\n\n\n\nLastly we will use the confidence interval formula to find the bounds for our 98% confidence interval.\n$$\nCI = \\bar{X} \\pm Z_{\\alpha/2} \\times \\frac{s}{\\sqrt{n}}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlower_confidence_boundary <- pga_round3_mean - z_cv * pga_round3_sd /\n  sqrt(pga_round3_n)\nupper_confidence_boundary <- pga_round3_mean + z_cv * pga_round3_sd /\n  sqrt(pga_round3_n)\npaste0(\"98% confidence interval: (\", lower_confidence_boundary,\n       \", \", upper_confidence_boundary, \")\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"98% confidence interval: (72.1152269671053, 73.9360550841767)\"\n```\n\n\n:::\n:::\n\n\n\n\n\nFinally we can interpret the confidence interval and say that we are 98% confident that the true mean of PGA Tour golfers' scores at the 2023 masters is between 72.1 and 73.9. \n\n:::\n\n\n\n::: {.callout-note title=\"Exercise 3: z-distribution confidence intervals\"}\n\nRun the code below to create the proper subset of the data for this exercise and calculate the sample mean, sample standard deviation, and critical value for the z-distribution.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npga_round1 <- masters_2023 |> \n  filter(round == 1, tour == \"PGA\")\nx_bar <- pga_round1 |> \n  summarise(mean(score)) |> \n  pull()\nsigma <- pga_round1 |> \n  summarise(sd(score)) |> \n  pull()\nz_cv <- qnorm(.975)\n```\n:::\n\n\n\n\nUse the formula for creating a confidence interval using the standard normal distribution to calculate the upper and lower limits of a confidence interval for the true mean of PGA professional scoring at Augusta using the PGA pros in the first round as our sample. Use a 95% confidence interval ($\\alpha = .05$).\n\na. Why can we use the **standard normal distribution** to calculate this confidence interval?\n\nb. What is the **confidence interval** for the true mean of scoring for PGA professionals at Augusta National?\n\nc. What is the **interpretation** of this confidence interval?\n\n:::\n\n## R for Single Mean Confidence Intervals\n\nR functions can help to speed up the process of finding these confidence intervals and will also help us with testing hypotheses later. The `t.test` function from the `stats` package makes a confidence interval for the t-distribution and the `z.test` function from the `BSDA` package does the same for the standard normal distribution.\n\nRun the code below to view what type of arguments these functions take, what they output, and the see some example uses\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n?t.test\n?z.test\n```\n:::\n\n\n\n\nThese functions return more than just a confidence interval. If we want to see just the confidence interval `$conf.int` should be used. Run the example below to see how this is done.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# t-test example\nseniors_round1 <- masters_2023 |> \n  filter(round == 1, tour == \"Senior\")\n\nt.test(seniors_round1$score, conf.level = .95)$conf.int\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 72.39194 79.03663\nattr(,\"conf.level\")\n[1] 0.95\n```\n\n\n:::\n\n```{.r .cell-code}\n# z-test example\npga_round2 <- masters_2023 |> \n  filter(round == 2, tour == \"PGA\")\n\n## Note that the Z test require the standard deviation to be passed in as an argument `sigma.x`\nz.test(pga_round2$score,\n       sigma.x = sd(pga_round2$score),\n       conf.level = .95)$conf.int\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 72.24391 73.71973\nattr(,\"conf.level\")\n[1] 0.95\n```\n\n\n:::\n:::\n\n\n\n\n::: column-margin\n**TIP**: The `$` operator is used to access a specific element of a list. In this case, the `conf.int` element of the list returned by the `t.test` and `z.test` functions. It can also be used to access elements of data frames and other objects in R. The line of code `seniors_round1$score` is used to access the `score` column of the `seniors_round1` data frame.\n:::\n\n::: column-margin\n**TIP**: Notice that the `z.test` function requires the standard deviation to be passed in as an argument `sigma.x`. Use the `sd()` function to calculate the standard deviation of the sample and use it as an estimate the population standard deviation.\n:::\n\n::: {.callout-note title=\"Exercise 4: R for confidence intervals\"}\n\na. Use the `t.test` function to find the confidence interval for amateur scoring using the `amateur_round1` sample from earlier in the lesson. What is the **confidence interval**?\n\n::: column-margin\n\n**TIP** If you didn't create the amateur_round1 sample earlier run the code below\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\namateur_round1 <- masters_2023 |> \n  filter(round == 1, tour == \"Amateur\")\n```\n:::\n\n\n\n\n**TIP** If you didn't create the pga_round1 sample earlier run the code below\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npga_round1 <- masters_2023 |> \n  filter(round == 1, tour == \"PGA\")\n```\n:::\n\n\n\n\n:::\n\nb. Use the `z.test` function to find the confidence interval for PGA professional scoring using the `pga_round1` sample from earlier in the lesson. What is the **confidence interval**?\n\nc. Are these confidence intervals the same as what you calculated manually earlier? If no, why might that be?\n\n:::\n\n# Hypothesis Testing with Single Mean Confidence Intervals\n\nHypothesis testing is a method used to determine if a claim about a population parameter is true or not. In this section, we will perform the most common type of hypothesis test, a single mean test. The null hypothesis ($H_0$) is that the population mean is equal to a specific value, and the alternative hypothesis ($H_a$) is that the population mean is not equal to that value, greater than that value, or less than that value.\n\nNull Hypothesis: $H_0: \\mu = \\mu_0$\n\nAlternative Hypothesis Options: \n\n$H_a: \\mu \\neq \\mu_0$ or\n\n$H_a: \\mu > \\mu_0$ or\n\n$H_a: \\mu < \\mu_0$\n\n\n## Test Statistics\n\nLike confidence intervals, we have two different tests for hypothesis testing for the population mean. Remember that if the population standard deviation is unknown and the sample size is less than 30, we use the t-distribution. If the population standard deviation is known or the sample size is greater than 30, we use the standard normal distribution.\n\nEach of these distributions have their own tests, the t-test and the z-test. This means that we have different test statistics to calculate depending on the situation.\n\n#### t-test\n\nThe t-test statistic is calculated using the formula:\n\n$$t = \\frac{\\bar{x} - \\mu_0}{\\frac{s}{\\sqrt{n}}}$$\n\nwhere $\\bar{x}$ is the sample mean, $\\mu_0$ is the hypothesized population mean, $s$ is the sample standard deviation, and $n$ is the sample size.\n\n#### z-test\n\nThe z-test statistic is calculated using the formula:\n\n$$z = \\frac{\\bar{x} - \\mu_0}{\\frac{\\sigma}{\\sqrt{n}}}$$\n\nwhere $\\bar{x}$ is the sample mean, $\\mu_0$ is the hypothesized population mean, $\\sigma$ is the population standard deviation, and $n$ is the sample size.\n\nOnce again, if the sample size is over 30 and the population standard deviation is unknown, we use the sample standard deviation to approximate the population standard deviation.\n\n## To Reject or Fail to Reject\n\nThere are two ways to make a decision about the null hypothesis. \n\n**Method 1**: **Critical values**, along with **test statistics**, can be used to determine if the **hypothesized population mean** is within the **confidence interval** for the true mean.\n\nA **critical value** is a value that separates the rejection region from the non-rejection region. The rejection region is the area where the null hypothesis is rejected. The non-rejection region is the area where the null hypothesis is not rejected. The critical value is determined by the significance level ($\\alpha$) and the degrees of freedom (if it is a t-test). The critical value is compared to the test statistic to determine if the null hypothesis should be rejected. If the test statistic is within the non-rejection region, the null hypothesis is not rejected. If the test statistic is within the rejection region, the null hypothesis is rejected and the alternative hypothesis is accepted.\n\nBelow is an example of using critical values and a test-statistic for a z-test with a 95% confidence level (two-sided). The critical value is 1.96. This means that if the test statistic is greater than 1.96 or less than -1.96, the null hypothesis is rejected. The blue represents the non-rejection region and the red the rejection region. Since the test statistic for this hypothetical example is 1.1 (less than 1.96 and greater than -1.96), we fail to reject the null hypothesis.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n\n\n\nThis method corresponds directly to the related confidence intervals produced for the sample data.\n\nIf the hypothesized population mean is within the confidence interval, we fail to reject the null hypothesis. If the hypothesized population mean is not within the confidence interval, the null hypothesis is rejected and the alternative hypothesis is accepted.\n\n::: column-margin\n\n**Note**: We can say that there is significant evidence to accept the alternative hypothesis if the null hypothesis is rejected. However, it should never be said that we accept the null hypothesis. We can only fail to reject it.\n\n:::\n\n**Method 2**: The second method is to use a p-value. The p-value is the probability of observing a test statistic as extreme as the one calculated from the sample data given that the null hypothesis is true. The p-value is compared to the significance level ($\\alpha$) to determine if the null hypothesis should be rejected. If the p-value is less than $\\alpha$, the null hypothesis is rejected. If the p-value is greater than $\\alpha$, the null hypothesis is not rejected.\n\n\n\n::: column-margin\n**NOTE**: Our **alternative hypothesis** determines whether we are looking for the probability that the test statistic is greater than or less than the observed value. \n\n- For a **two-sided test**, the p-value is the probability that the test statistic is greater than the observed value or less than the negative of the observed value. Find the area in one of the tails and double it.\n\n- For a **left-tailed test** ($H_a: \\mu < \\mu_0$), the p-value is the probability that the test statistic is less than the observed value.\n\n- For a **right-tailed test** ($H_a: \\mu > \\mu_0$), the p-value is the probability that the test statistic is greater than the observed value.\n:::\n\nFirst let's visualize what a p-value is telling us. \n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n\n\n\nNow let's see how we can calculate p-value for our example using `R`. We have a hypothetical z-test statistic of 1.1 and alpha of .05 for a two-tailed test. We want to find the probability of getting a test statistic less than -1.1 or greater than 1.1. In `R` the `pnorm` function calculates the probability that a test statistic is less than a given value. Since we know that the z-distribution is symmetrical we can simply multiply the probability that the test statistic is less than -1.1 by 2 to get our p-value.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_value <- pnorm(-1.1) * 2\np_value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.2713321\n```\n\n\n:::\n:::\n\n\n\n\nSince the p-value is greater than our alpha value of .05 we fail to reject the null hypothesis.\n\n## Hypothesis testing in R\n\nThankfully R can help us with this as well. The `t.test` function and the `z.test` function can both perform hypothesis tests, without having to do each step manually.\n\nThe code below tests if the true mean is not equal to 50 given that the `example_vector` is our sample. The confidence level is set to 95%.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexample_vector <- seq(10, 100, by = 10)\nt.test(example_vector, mu = 50, alternative = \"two.sided\", conf.level = .95)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  example_vector\nt = 0.52223, df = 9, p-value = 0.6141\nalternative hypothesis: true mean is not equal to 50\n95 percent confidence interval:\n 33.34149 76.65851\nsample estimates:\nmean of x \n       55 \n```\n\n\n:::\n:::\n\n\n\n\nAs can be seen in the output of the code above, the p-value is 0.61, which is much greater than the significance level of 0.05. The test-statistic is 0.522 which is within the non-rejection region since critical values for this test would be -2.26 and 2.26. Therefore, we fail to reject the null hypothesis.\n\n## Hypothesizing Par as the Population Mean\n\n::: column-margin\n\nAugusta National is breathtakingly beautiful, but if golfers get distracted by the scenic views, tall pines, bunkers, water, and azaleas may catch their balls. \n\n![Augusta Hole 13](augusta-national-13.jpg)\n\nImage Source: [Your Golf Travel](https://www.yourgolftravel.com/golf-architects/alister-mackenzie-golf-courses), [CC 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)\n\n:::\n\nIn golf par is considered to be the number of strokes a good golfer is expected to take. The par for the course at Augusta National is 72. It is known that Augusta National is a tougher than usual course but we would like to test if that is the case for different groups. \n\nOur null hypothesis will generally be that the mean of the group is equal to 72.\n\n\n::: {.callout-note title=\"Exercise 5: t-test for single mean hypothesis testing\"}\n\n::: column-margin\n\nAmateurs generally struggle in the Masters, but in 2023 Sam Bennett, a Texas A&M student, made the cut and finished 16th. However, due to his amateur status, he was not eligible to win money and missed out on $261,000. \n\n:::\n\nAmateurs, who are not yet professional golfers, are generally expected to score higher than professionals. We would like to test if the mean of amateur scoring is above par at Augusta National\n\na. What is the **null hypothesis** for this test?\n\nb. What is the **alternative hypothesis** for this test?\n\nc. Use the `t.test` function to test if the mean of amateur scoring is greater than 72 using the `amateur_round1` sample from earlier in the lesson. What is the **p-value**?\n\nd. Based on the p-value, is there statistically significant evidence that the mean of amateur scoring is greater than 72?\n\n:::\n\n\n::: {.callout-note title=\"Exercise 6: z-test for single mean hypothesis testing\"}\n\nPGA professionals would generally average somewhere around par. We would like to test if the mean of PGA professional scoring is not equal to 72 at Augusta National.\n\na. What is the **null hypothesis** for this test?\n\nb. What is the **alternative hypothesis** for this test?\n\n::: column-margin\n\n**TIP** Use the `$score` column from the `pga_round1` sample as the first argument in the `z.test` function\n\n**TIP** Remember that the `z.test` function requires the population standard deviation as the second argument. Use the `sd` function to calculate the standard deviation of the `pga_round1` sample.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsd(pga_round1$score)\n```\n:::\n\n\n\n\n:::\n\nc. Use the `z.test` function to test if the mean of PGA professional scoring is not equal to 72 using the `pga_round1` sample from earlier in the lesson. What is the **p-value**?\n\nd. Based on the confidence interval, is there statistically significant evidence that the mean of PGA professional scoring is not equal to 72?\n\ne. Explain your answer to part **d**.\n\n:::\n\n# More practice\n\nIf you would like more practice with confidence intervals and hypothesis testing, try the following exercises.\n\n::: {.callout-note title=\"Challenge 1: Critical Values Knowledge Check\"}\n\n::: column-margin\n\n\n\n\n\n\n\n\n\n**Fun fact**: In the 2023 Masters Tournament, the average score for LIV golfers was just slightly worse (72.91) than the average score for PGA golfers (72.55). However, the average score for amateurs (74.56) and seniors (76.31) was significantly higher.\n\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nliv_round3 <- masters_2023 |> \n  filter(round == 3, tour == \"LIV\")\n```\n:::\n\n\n\n\na. What is the degrees of freedom for a single mean hypothesis test for the above sample of Augusta National scores?\n\nb. Which of the following is the correct formula for the test statistic for a single mean hypothesis test for the above sample?\n\n1. $t = \\frac{\\bar{X} - \\mu_0}{\\frac{S}{\\sqrt{n}}}$\n2. $z = \\frac{\\bar{X} - \\mu_0}{\\frac{\\sigma}{\\sqrt{n}}}$\n\nc. Assume that the alternate hypothesis is that the true mean of scoring for LIV golfers at Augusta is greater than 72. Use the correct formula from part **b** to calculate the test statistic for the above sample manually. What is the value of the **test statistic**?\n\nd. Assuming $\\alpha = 0.05$, what is the **critical value** for the above sample?\n\ne. Based on the test statistic and critical value, what is your **conclusion**?\n\n:::\n\n::: {.callout-note title=\"Challenge 2: P-Value Knowledge check\"}\n\nAnswer the following questions based on the sample of Augusta National scores below.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npro_round4 <- masters_2023 |> \n  filter(round == 4, tour == \"PGA\")\n```\n:::\n\n\n\n\n::: column-margin\n\n**TIP**: Check the number of observations in the `pro_round4` sample using the `nrow` function, by looking in your global environment, or by using the `glimpse` function in order to determine the correct function to use.\n\n:::\n\na. Use the proper function to test if the mean of the sample is equal to 72. What is the **p-value**?\n\nb. Based on the p-value, what would be your **conclusion** if $\\alpha = 0.01$?\n\nc. Based on the p-value, what would be your **conclusion** if $\\alpha = 0.05$?\n\nd. Based on the p-value, what would be your **conclusion** if $\\alpha = 0.10$?\n\ne. Based on the p-value, what would be your **conclusion** if $\\alpha = 0.20$?\n\nf. What is wrong with doing multiple hypothesis tests with different $\\alpha$ values that you choose after the fact?\n\n:::\n\n::: {.callout-note title=\"Challenge 3: Confidence Intervals Knowledge Check\"}\n\nAnswer the following questions based on the 2 samples of Augusta National scores below.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Sample 1\namateur_round2 <- masters_2023 |> \n  filter(round == 2, tour == \"Amateur\")\n\n## Sample 2\npga_rounds2_4 <- masters_2023 |> \n  filter(round %in% c(1, 2), tour == \"PGA\")\n```\n:::\n\n\n\n\na. How many observations are in sample 1?\n\nb. How many observations are in sample 2?\n\nc. Which of the above samples (sample 1 or sample 2) would you expect to have a **wider confidence interval** for the mean? Why?\n\nd. How does the **sample size** affect the width of the confidence interval?\n\ne. Explain why you answered the way you did in part **b**.\n\nf. Using sample 2, if confidence intervals were made for confidence levels of 90%, 95%, and 99%, which confidence interval would be the **widest**?\n\ng. What is the **relationship** between the confidence level and the width of the confidence interval?\n\n:::\n\n::: {.callout-note title=\"Challenge 4: z vs t (large sample size)\"}\n\nYou have the following sample of Augusta National scores below. Answer the following questions based on the sample.\n\n::: column-margin\n\n\n\n\n\n\n\n\n\n**Think on it**: The average score for the first 2 rounds of the 2023 Masters Tournament was 72.8, while the average score for the last 2 rounds was 73.22. This is interesting because only the top players make it to the last 2 rounds, so you would expect the scores to be lower. What could have changed so that the best players are now scoring worse?\n\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npga_rounds1_2 <- masters_2023 |> \n  filter(round %in% c(1, 2), tour == \"PGA\")\n```\n:::\n\n\n\n\na. Create a **95% confidence interval** for the mean of the sample using the `z.test` function. What is the **confidence interval**?\n\nb. Create a **95% confidence interval** for the mean of the sample using the `t.test` function. What is the **confidence interval**?\n\nc. Which of the above confidence intervals is **wider**?\n\nd. Based on your answer to the above question, would you say a t-distribution has **heavier** or **lighter** tailed than a z-distribution?\n\ne. Is the difference in the **confidence intervals** in this problem likely to change a result in a hypothesis test? Why or why not?\n\n:::\n\n# Conclusion\n\nIn this module you have learned about single mean confidence intervals and single mean hypothesis tests. You have learned when to use a z-distribution and when to use a t-distribution. How to interpret p-values and confidence intervals was also covered.\n\nWith the Masters scoring data, you were able to calculate confidence intervals and test hypotheses about the mean score of different groups of golfers. We saw that in order to form confidence intervals for groups such as amateurs and seniors, we needed to use the t-distribution due to the small sample sizes. With larger sample sizes, such as the PGA golfers, we were able to use the z-distribution. These confidence intervals gave us a range of plausible values for the true mean score of each group. We also tested hypotheses about the mean scoring averages for PGA, LIV, and amateur golfers. We were able to make conclusions about the mean score of each group (whether or not that group's mean was greater than or not equal to par) based on the p-values of the hypothesis tests.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}